---
name: search
description: AI Search and Downloading Agent for solving complex deepsearch tasks using MCP tools (playwright, documents, search, terminal, etc.). You may use this agent for running GAIA-style benchmarks, multi-step research, document handling and downloading, or code execution.
mcp_servers: ["csv", "docx", "download", "xlsx", "image", "pdf", "pptx", "search", "terminal", "txt", "ms-playwright"]
mcp_config: {"mcpServers": {"csv": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.documents.mscsv"], "env": {}, "client_session_timeout_seconds": 9999.0}, "docx": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.documents.msdocx"], "env": {}, "client_session_timeout_seconds": 9999.0}, "download": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.tools.download"], "env": {}, "client_session_timeout_seconds": 9999.0}, "xlsx": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.documents.msxlsx"], "env": {}, "client_session_timeout_seconds": 9999.0}, "image": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.media.image"], "env": {}, "client_session_timeout_seconds": 9999.0}, "pdf": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.documents.pdf"], "env": {}, "client_session_timeout_seconds": 9999.0}, "pptx": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.documents.mspptx"], "env": {}, "client_session_timeout_seconds": 9999.0}, "search": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.tools.search"], "env": {"GOOGLE_API_KEY": "${GOOGLE_API_KEY}", "GOOGLE_CSE_ID": "${GOOGLE_CSE_ID}"}, "client_session_timeout_seconds": 9999.0}, "terminal": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.tools.terminal"]}, "txt": {"command": "python", "args": ["-m", "examples.gaia.mcp_collections.documents.txt"], "env": {}, "client_session_timeout_seconds": 9999.0}, "ms-playwright": {"command": "npx", "args": ["@playwright/mcp@latest", "--no-sandbox", "--isolated", "--output-dir=/tmp/playwright", "--timeout-action=10000"], "env": {"PLAYWRIGHT_TIMEOUT": "120000", "SESSION_REQUEST_CONNECT_TIMEOUT": "120"}}}}
---

You are an all-capable AI assistant aimed at solving any task presented by the user.

## 1. Self Introduction
*   **Name:** DeepResearch Team.
*   **Knowledge Boundary:** Do not mention your LLM model or other specific proprietary models outside your defined role.

## 2. Methodology & Workflow
Complex tasks must be solved step-by-step using a generic ReAct (Reasoning + Acting) approach:
0.  **Module Dependency Install:** If relevant modules are missing, use the terminal tool to install the appropriate module.
1.  **Task Analysis:** Break down the user's request into sub-tasks.
2.  **Tool Execution:** Select and use the appropriate tool for the current sub-task.
3.  **Analysis:** Review the tool's output. If the result is insufficient, try a different approach or search query.
4.  **Iteration:** Repeat the loop until you have sufficient information.
5.  **Final Answer:** Conclude with the final formatted response.

## 3. Critical Guardrails
1.  **Tool Usage:**
    *   **During Execution:** Every response MUST contain exactly one tool call. Do not chat without acting until the task is done.
    *   **Completion:** If the task is finished, your VERY NEXT and ONLY action is to provide the final answer in the `<answer>` tag. Do not call any tool once the task is solved.
    *   **Web Browser Use:** You need ms-playwright tool to help you browse web (click, scroll, type, search and so on), to search certain image (for example) that by simply using google search may not return a satisfying result.
2.  **Time Sensitivity:**
    *   Today's date is provided at runtime (Asia/Shanghai timezone). Your internal knowledge cut-off is 2024. For questions regarding current dates, news, or rapidly evolving technology, use the `search` tool to fetch the latest information.
3.  **Language:** Ensure your final answer and reasoning style match the user's language.
4.  **File & Artifact Management (CRITICAL):**
    *   **Unified Workspace:** The current working directory is your **one and only** designated workspace.
    *   **Execution Protocol:** All artifacts you generate and download (code scripts, documents, data, images, etc.) **MUST** be saved directly into the current working directory. You can use the `terminal` tool with the `pwd` command at any time to confirm your current location.
    *   **Strict Prohibition:** **DO NOT create any new subdirectories** (e.g., `./output`, `temp`, `./results`). All files MUST be placed in the top-level current directory where the task was initiated.
    *   **Rationale:** This strict policy ensures all work is organized, immediately accessible to the user, and prevents polluting the file system with nested folders.


# ğŸ–¼ï¸ Image Search & Download Utility

é€šç”¨å›¾ç‰‡æœç´¢å’Œæ‰¹é‡ä¸‹è½½å·¥å…·ï¼Œæ”¯æŒé€šè¿‡å…³é”®è¯æœç´¢å¹¶æ‰¹é‡ä¸‹è½½å›¾ç‰‡ã€‚

## Features

1. **è‡ªåŠ¨åˆ›å»ºä¸‹è½½ç›®å½•** - è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹å­˜å‚¨å›¾ç‰‡
2. **å›¾ç‰‡æœç´¢** - è°ƒç”¨å›¾ç‰‡æœç´¢ API è·å–å›¾ç‰‡åˆ—è¡¨
3. **æ‰¹é‡ä¸‹è½½** - ä»æœç´¢ç»“æœä¸­ä¸‹è½½æŒ‡å®šæ•°é‡çš„å›¾ç‰‡
4. **é”™è¯¯å¤„ç†** - ä¼˜é›…å¤„ç†ç½‘ç»œé”™è¯¯å’Œä¸‹è½½å¤±è´¥
5. **å¯é…ç½®å‚æ•°** - æ”¯æŒè‡ªå®šä¹‰æœç´¢å…³é”®è¯ã€ä¸‹è½½ç›®å½•ã€æ•°é‡ç­‰

## Usage

ä½¿ç”¨ä»¥ä¸‹ Python å‡½æ•°è¿›è¡Œå›¾ç‰‡æœç´¢å’Œä¸‹è½½ï¼š

```python
import requests
import os
import urllib.parse
import time
import json
from typing import Optional, List, Dict

def fix_json_escape_sequences(content: str) -> str:
    r"""
    ä¿®å¤ JSON ä¸­çš„æ— æ•ˆè½¬ä¹‰åºåˆ—
    
    JSON ä¸­æœ‰æ•ˆçš„è½¬ä¹‰åºåˆ—: \", \\, \/, \b, \f, \n, \r, \t, \uXXXX
    æ— æ•ˆçš„è½¬ä¹‰åºåˆ—ï¼ˆå¦‚ \'ï¼‰éœ€è¦ä¿®å¤
    """
    # ä¿®å¤æ— æ•ˆçš„å•å¼•å·è½¬ä¹‰ \' -> '
    content = content.replace("\\'", "'")

    # é€å­—ç¬¦å¤„ç†ä»¥ç¡®ä¿æ‰€æœ‰åæ–œæ è½¬ä¹‰éƒ½æ˜¯æœ‰æ•ˆçš„
    result = []
    i = 0
    while i < len(content):
        if content[i] == '\\' and i + 1 < len(content):
            next_char = content[i + 1]
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„è½¬ä¹‰åºåˆ—
            if next_char in ['"', '\\', '/', 'b', 'f', 'n', 'r', 't', 'u']:
                # æœ‰æ•ˆçš„è½¬ä¹‰åºåˆ—
                if next_char == 'u' and i + 5 < len(content):
                    # Unicode è½¬ä¹‰åºåˆ— \uXXXX
                    unicode_part = content[i+2:i+6]
                    try:
                        # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„åå…­è¿›åˆ¶
                        int(unicode_part, 16)
                        result.append(content[i:i+6])
                        i += 6
                        continue
                    except ValueError:
                        # æ— æ•ˆçš„ Unicode è½¬ä¹‰ï¼Œè½¬ä¹‰åæ–œæ æœ¬èº«
                        result.append('\\\\')
                        result.append(next_char)
                        i += 2
                        continue
                else:
                    # å…¶ä»–å•å­—ç¬¦è½¬ä¹‰åºåˆ—
                    result.append(content[i:i+2])
                    i += 2
                    continue
            else:
                # æ— æ•ˆçš„è½¬ä¹‰åºåˆ—ï¼Œè½¬ä¹‰åæ–œæ æœ¬èº«
                result.append('\\\\')
                result.append(next_char)
                i += 2
                continue
        else:
            result.append(content[i])
            i += 1

    return ''.join(result)

def safe_json_loads(content: str):
    """
    å®‰å…¨è§£æ JSONï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ä¿®å¤è½¬ä¹‰åºåˆ—åé‡è¯•
    
    Args:
        content: JSON å­—ç¬¦ä¸²å†…å®¹
        
    Returns:
        è§£æåçš„ Python å¯¹è±¡
        
    Raises:
        json.JSONDecodeError: ä¿®å¤åä»ç„¶è§£æå¤±è´¥æ—¶æŠ›å‡º
    """
    # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤è½¬ä¹‰åºåˆ—
        print(f'JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤è½¬ä¹‰åºåˆ—... (é”™è¯¯ä½ç½®: è¡Œ {e.lineno}, åˆ— {e.colno})')
        fixed_content = fix_json_escape_sequences(content)
        try:
            return json.loads(fixed_content)
        except json.JSONDecodeError as e2:
            print(f'ä¿®å¤åä»ç„¶å¤±è´¥: {e2} (é”™è¯¯ä½ç½®: è¡Œ {e2.lineno}, åˆ— {e2.colno})')
            raise

def search_and_download_images(
    search_query: str,
    download_dir: str = 'downloaded_images',
    download_count: int = 10,
    image_quality: str = 'thumbURL',
    page_num: int = 0,
    results_per_page: int = 30,
    request_delay: float = 1.0,
    timeout: int = 10
) -> Dict[str, any]:
    """
    æœç´¢å¹¶ä¸‹è½½å›¾ç‰‡
    
    Args:
        search_query: æœç´¢å…³é”®è¯
        download_dir: ä¸‹è½½ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ä¸º 'downloaded_images'ï¼‰
        download_count: è¦ä¸‹è½½çš„å›¾ç‰‡æ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰
        image_quality: å›¾ç‰‡è´¨é‡é€‰é¡¹ï¼Œå¯é€‰ 'thumbURL', 'middleURL', 'objURL'ï¼ˆé»˜è®¤ 'thumbURL'ï¼‰
        page_num: åˆ†é¡µèµ·å§‹ä½ç½®ï¼ˆé»˜è®¤ 0ï¼‰
        results_per_page: æ¯é¡µç»“æœæ•°ï¼Œæœ€å¤§ 30ï¼ˆé»˜è®¤ 30ï¼‰
        request_delay: è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚ï¼ˆé»˜è®¤ 1.0ï¼‰
        timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ˆé»˜è®¤ 10ï¼‰
        
    Returns:
        åŒ…å«ä¸‹è½½ç»“æœçš„å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹é”®ï¼š
        - 'success': æ˜¯å¦æˆåŠŸ
        - 'downloaded': æˆåŠŸä¸‹è½½çš„å›¾ç‰‡æ•°é‡
        - 'total_found': æ‰¾åˆ°çš„å›¾ç‰‡æ€»æ•°
        - 'download_dir': ä¸‹è½½ç›®å½•è·¯å¾„
        - 'errors': é”™è¯¯ä¿¡æ¯åˆ—è¡¨
    """
    result = {
        'success': False,
        'downloaded': 0,
        'total_found': 0,
        'download_dir': download_dir,
        'errors': []
    }
    
    # åˆ›å»ºä¸‹è½½ç›®å½•
    os.makedirs(download_dir, exist_ok=True)
    
    # æ„å»ºæœç´¢ URL
    encoded_query = urllib.parse.quote(search_query)
    search_url = (
        f'https://image.baidu.com/search/acjson?'
        f'tn=resultjson_com&logid=&ipn=rj&ct=201326592&is=&fp=result&fr=&'
        f'word={encoded_query}&queryWord={encoded_query}&cl=2&lm=-1&'
        f'ie=utf-8&oe=utf-8&adpicid=&st=-1&z=&ic=&hd=&latest=&copyright=&'
        f's=&se=&tab=&width=&height=&face=0&istype=2&qc=&nc=1&expermode=&'
        f'nojc=&isAsync=&pn={page_num}&rn={results_per_page}&gsm=1e'
    )
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Referer': 'https://image.baidu.com/'
    }
    
    try:
        response = requests.get(search_url, headers=headers, timeout=timeout)
        print(f'æœç´¢å“åº”çŠ¶æ€: {response.status_code}')
        
        if response.status_code == 200:
            # ä½¿ç”¨å®‰å…¨è§£æå‡½æ•°è‡ªåŠ¨å¤„ç†è½¬ä¹‰åºåˆ—é—®é¢˜
            data = safe_json_loads(response.text)
            if 'data' in data and isinstance(data['data'], list):
                images = data['data']
                result['total_found'] = len(images)
                print(f'æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡')
                
                downloaded = 0
                for i, img in enumerate(images[:download_count]):
                    # æ ¹æ®æŒ‡å®šçš„å›¾ç‰‡è´¨é‡é€‰æ‹© URL
                    img_url = None
                    if image_quality in img:
                        img_url = img[image_quality]
                    elif 'thumbURL' in img:
                        img_url = img['thumbURL']
                    elif 'middleURL' in img:
                        img_url = img['middleURL']
                    elif 'objURL' in img:
                        img_url = img['objURL']
                    
                    if img_url:
                        try:
                            img_response = requests.get(img_url, headers=headers, timeout=timeout)
                            if img_response.status_code == 200:
                                # è·å–æ–‡ä»¶æ‰©å±•å
                                file_ext = 'jpg'
                                if '.' in img_url:
                                    ext = img_url.split('.')[-1].split('?')[0].lower()
                                    if ext in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
                                        file_ext = ext
                                
                                filename = f'{download_dir}/image_{i+1}.{file_ext}'
                                with open(filename, 'wb') as f:
                                    f.write(img_response.content)
                                print(f'å·²ä¸‹è½½: {filename}')
                                downloaded += 1
                                time.sleep(request_delay)  # é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                            else:
                                error_msg = f'ä¸‹è½½å›¾ç‰‡ {i+1} å¤±è´¥: HTTP {img_response.status_code}'
                                print(error_msg)
                                result['errors'].append(error_msg)
                        except Exception as e:
                            error_msg = f'ä¸‹è½½å›¾ç‰‡ {i+1} å¤±è´¥: {e}'
                            print(error_msg)
                            result['errors'].append(error_msg)
                    else:
                        error_msg = f'å›¾ç‰‡ {i+1} æ²¡æœ‰å¯ç”¨çš„ URL'
                        print(error_msg)
                        result['errors'].append(error_msg)
                
                result['downloaded'] = downloaded
                result['success'] = True
                print(f'æˆåŠŸä¸‹è½½ {downloaded} å¼ å›¾ç‰‡ï¼Œå…±æ‰¾åˆ° {len(images)} å¼ ')
            else:
                error_msg = 'æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®'
                print(error_msg)
                result['errors'].append(error_msg)
        else:
            error_msg = f'æœç´¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}'
            print(error_msg)
            result['errors'].append(error_msg)
            
    except Exception as e:
        error_msg = f'æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}'
        print(error_msg)
        result['errors'].append(error_msg)
    
    return result

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨
    result = search_and_download_images(
        search_query='è‡ªç„¶é£æ™¯',
        download_dir='landscape_photos',
        download_count=5
    )
    
    # ç¤ºä¾‹ 2: ä½¿ç”¨é«˜è´¨é‡å›¾ç‰‡
    result = search_and_download_images(
        search_query='åŸå¸‚å»ºç­‘',
        download_dir='city_buildings',
        download_count=10,
        image_quality='objURL',  # ä½¿ç”¨åŸå§‹å›¾ç‰‡ URL
        request_delay=1.5  # å¢åŠ è¯·æ±‚é—´éš”
    )
    
    # ç¤ºä¾‹ 3: ä¸‹è½½æ›´å¤šå›¾ç‰‡
    result = search_and_download_images(
        search_query='åŠ¨ç‰©',
        download_dir='animals',
        download_count=20,
        page_num=0,
        results_per_page=30
    )
```

## å‡½æ•°å‚æ•°

| å‚æ•° | ç±»å‹ | æè¿° | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|------|--------|------|
| `search_query` | str | æœç´¢å…³é”®è¯ï¼ˆå¿…éœ€ï¼‰ | - | `'è‡ªç„¶é£æ™¯'` |
| `download_dir` | str | ä¸‹è½½ä¿å­˜ç›®å½• | `'downloaded_images'` | `'my_photos'` |
| `download_count` | int | è¦ä¸‹è½½çš„å›¾ç‰‡æ•°é‡ | `10` | `20` |
| `image_quality` | str | å›¾ç‰‡è´¨é‡é€‰é¡¹ï¼š'thumbURL'ï¼ˆç¼©ç•¥å›¾ï¼‰ã€'middleURL'ï¼ˆä¸­ç­‰ï¼‰ã€'objURL'ï¼ˆåŸå§‹ï¼‰ | `'thumbURL'` | `'objURL'` |
| `page_num` | int | åˆ†é¡µèµ·å§‹ä½ç½® | `0` | `30` |
| `results_per_page` | int | æ¯é¡µç»“æœæ•°ï¼ˆæœ€å¤§ 30ï¼‰ | `30` | `30` |
| `request_delay` | float | è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ | `1.0` | `1.5` |
| `timeout` | int | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ | `10` | `15` |

## è¿”å›å€¼

å‡½æ•°è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

- `success` (bool): æ˜¯å¦æˆåŠŸæ‰§è¡Œ
- `downloaded` (int): æˆåŠŸä¸‹è½½çš„å›¾ç‰‡æ•°é‡
- `total_found` (int): æ‰¾åˆ°çš„å›¾ç‰‡æ€»æ•°
- `download_dir` (str): ä¸‹è½½ç›®å½•è·¯å¾„
- `errors` (list): é”™è¯¯ä¿¡æ¯åˆ—è¡¨

## API å‚æ•°è¯´æ˜

ç™¾åº¦å›¾ç‰‡æœç´¢ API çš„ä¸»è¦å‚æ•°ï¼š
- `word` / `queryWord`: æœç´¢å…³é”®è¯ï¼ˆURL ç¼–ç ï¼‰
- `pn`: åˆ†é¡µèµ·å§‹ä½ç½®ï¼ˆä» 0 å¼€å§‹ï¼‰
- `rn`: æ¯é¡µç»“æœæ•°ï¼ˆæœ€å¤§ 30ï¼‰

## æ³¨æ„äº‹é¡¹

1. **è¯·æ±‚é¢‘ç‡**: å»ºè®®è®¾ç½® 1 ç§’ä»¥ä¸Šçš„è¯·æ±‚é—´éš”ï¼Œé¿å…è§¦å‘åçˆ¬è™«é™åˆ¶
2. **User-Agent**: å¿…é¡»æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚å¤´
3. **Referer**: å¿…é¡»è®¾ç½®ç™¾åº¦å›¾ç‰‡åŸŸåä½œä¸º referrer
4. **è¶…æ—¶è®¾ç½®**: å»ºè®®è®¾ç½® 10 ç§’è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
5. **å›¾ç‰‡è´¨é‡**: 
   - `thumbURL`: ç¼©ç•¥å›¾ï¼ˆæœ€å°ï¼Œä¸‹è½½å¿«ï¼‰
   - `middleURL`: ä¸­ç­‰è´¨é‡ï¼ˆæ¨èï¼‰
   - `objURL`: åŸå§‹å›¾ç‰‡ï¼ˆæœ€å¤§ï¼Œå¯èƒ½å¤±æ•ˆï¼‰
6. **ä¸‹è½½é™åˆ¶**: å»ºè®®å•æ¬¡ä¸‹è½½ä¸è¶…è¿‡ 30 å¼ å›¾ç‰‡ï¼Œé¿å…è¢«é™åˆ¶
7. **æ–‡ä»¶æ‰©å±•å**: è‡ªåŠ¨è¯†åˆ«å›¾ç‰‡æ ¼å¼ï¼ˆjpg, png, gif, webp ç­‰ï¼‰