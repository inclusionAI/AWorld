#!/usr/bin/env python3
"""
åˆ†æè½¨è¿¹æ–‡ä»¶ä¸­çš„å·¥å…·è°ƒç”¨å’ŒLLMè°ƒç”¨çš„è€—æ—¶åˆ†å¸ƒ
"""
import json
import ast
import os
import glob
import re
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Any, Tuple
import statistics
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
try:
    import matplotlib.font_manager as fm
    # è·å–æ‰€æœ‰å¯ç”¨å­—ä½“
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    # ä¼˜å…ˆä½¿ç”¨çš„ä¸­æ–‡å­—ä½“åˆ—è¡¨
    preferred_fonts = ['PingFang SC', 'STHeiti', 'SimHei', 'Microsoft YaHei', 
                       'Arial Unicode MS', 'WenQuanYi Micro Hei', 'Noto Sans CJK SC']
    
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
    chinese_font = None
    for font in preferred_fonts:
        if font in available_fonts:
            chinese_font = font
            break
    
    if chinese_font:
        matplotlib.rcParams['font.sans-serif'] = [chinese_font] + matplotlib.rcParams['font.sans-serif']
except Exception:
    # é™é»˜ä½¿ç”¨é»˜è®¤å­—ä½“
    matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']

matplotlib.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

def parse_time(time_str: str) -> datetime:
    """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
    return datetime.fromisoformat(time_str)

def calculate_duration(start_time: str, end_time: str) -> float:
    """è®¡ç®—è€—æ—¶ï¼ˆç§’ï¼‰ï¼Œç¡®ä¿è¿”å›æ­£å€¼"""
    start = parse_time(start_time)
    end = parse_time(end_time)
    duration = (end - start).total_seconds()
    # å¦‚æœè®¡ç®—å‡ºæ¥æ˜¯è´Ÿæ•°ï¼Œå–ç»å¯¹å€¼ï¼ˆå¯èƒ½æ˜¯æ—¶é—´æˆ³é¡ºåºé—®é¢˜ï¼‰
    return abs(duration)

def detect_blocking_issues(content_str: str) -> Dict[str, Any]:
    """æ£€æµ‹å†…å®¹ä¸­çš„æ‹¦æˆªé—®é¢˜ï¼ˆç™»å½•ã€éªŒè¯ç ã€åçˆ¬è™«ï¼‰
    
    è¿”å›:
        {
            'is_blocked': bool,
            'block_reasons': List[str],  # æ‰€æœ‰æ‹¦æˆªåŸå› åˆ—è¡¨
            'has_answer': bool,
            'login_blocked': bool,
            'captcha_blocked': bool,
            'anti_bot_blocked': bool
        }
    """
    content_lower = content_str.lower()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ <answer> æ ‡ç­¾
    has_answer = False
    answer_match = re.search(r'<answer>(.*?)</answer>', content_str, re.IGNORECASE | re.DOTALL)
    if answer_match:
        answer_content = answer_match.group(1).strip()
        # åªè¦æœ‰answeræ ‡ç­¾å°±ç®—æœ‰ç­”æ¡ˆ
        if answer_content or True:
            has_answer = True
    
    # æ£€æŸ¥æ‹¦æˆªå…³é”®è¯
    blocked_keywords = {
        'login': [r'ç™»å½•', r'login', r'sign\s*in', r'éœ€è¦ç™»å½•', r'è¯·ç™»å½•', r'æœªç™»å½•', r'è¯·å…ˆç™»å½•'],
        'captcha': [r'éªŒè¯ç ', r'captcha', r'verification', r'äººæœºéªŒè¯', r'å®‰å…¨éªŒè¯', r'è¯·å®ŒæˆéªŒè¯', 
                   r'æ‹–åŠ¨æ»‘å—', r'drag.*slider', r'please drag', r'éªŒè¯ç éªŒè¯', r'éªŒè¯ç å¼¹çª—', r'éªŒè¯ç è¦æ±‚'],
        'anti_bot': [r'åçˆ¬è™«', r'anti.*bot', r'blocked', r'forbidden', r'\b403\b', r'\b429\b', 
                    r'è®¿é—®è¢«æ‹’ç»', r'è¯·æ±‚è¿‡äºé¢‘ç¹', r'rate limit', r'è®¿é—®å—é™'],
    }
    
    block_reasons = []
    login_blocked = False
    captcha_blocked = False
    anti_bot_blocked = False
    
    for reason, patterns in blocked_keywords.items():
        for pattern in patterns:
            if re.search(pattern, content_lower, re.IGNORECASE):
                if reason not in block_reasons:
                    block_reasons.append(reason)
                if reason == 'login':
                    login_blocked = True
                elif reason == 'captcha':
                    captcha_blocked = True
                elif reason == 'anti_bot':
                    anti_bot_blocked = True
                break
    
    is_blocked = len(block_reasons) > 0
    
    return {
        'is_blocked': is_blocked,
        'block_reasons': block_reasons,
        'has_answer': has_answer,
        'login_blocked': login_blocked,
        'captcha_blocked': captcha_blocked,
        'anti_bot_blocked': anti_bot_blocked
    }

def analyze_single_trajectory(file_path: str, silent: bool = False):
    """åˆ†æå•ä¸ªè½¨è¿¹æ–‡ä»¶ï¼Œè¿”å›ç»Ÿè®¡æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå› ä¸ºæ–‡ä»¶å¯èƒ½æ˜¯Pythonå­—å…¸æ ¼å¼è€Œä¸æ˜¯æ ‡å‡†JSON
        content = f.read()
        # å°è¯•ä½¿ç”¨ast.literal_evalè§£æPythonå­—å…¸æ ¼å¼
        try:
            data = ast.literal_eval(content)
        except (ValueError, SyntaxError):
            # å¦‚æœä¸æ˜¯Pythonæ ¼å¼ï¼Œå°è¯•JSON
            try:
                data = json.loads(content)
            except json.JSONDecodeError as e:
                raise ValueError(f"æ— æ³•è§£ææ–‡ä»¶ {file_path}: æ—¢ä¸æ˜¯æœ‰æ•ˆçš„Pythonå­—å…¸ä¹Ÿä¸æ˜¯JSONæ ¼å¼") from e
    
    # æ£€æµ‹æ‹¦æˆªé—®é¢˜
    content_str = str(data)
    blocking_info = detect_blocking_issues(content_str)
    
    llm_durations = []  # LLMè°ƒç”¨è€—æ—¶
    tool_durations = []  # å·¥å…·è°ƒç”¨è€—æ—¶
    tool_type_durations = defaultdict(list)  # æŒ‰å·¥å…·ç±»å‹åˆ†ç±»çš„è€—æ—¶
    
    # éå†æ‰€æœ‰æ¡ç›®
    for key, entry in data.items():
        if not isinstance(entry, dict):
            continue
            
        metadata = entry.get('metadata', {})
        role = entry.get('role', '')
        start_time = metadata.get('start_time')
        end_time = metadata.get('end_time')
        
        if not start_time or not end_time:
            continue
        
        duration = calculate_duration(start_time, end_time)
        
        # åˆ¤æ–­æ˜¯LLMè°ƒç”¨è¿˜æ˜¯å·¥å…·è°ƒç”¨
        if role == 'assistant':
            # assistantè§’è‰²ä¸”æ²¡æœ‰tool_call_idçš„æ˜¯LLMè°ƒç”¨
            tool_call_id = metadata.get('tool_call_id')
            if not tool_call_id:
                llm_durations.append(duration)
        elif role == 'tool':
            # toolè§’è‰²æ˜¯å·¥å…·è°ƒç”¨
            tool_durations.append(duration)
            # è·å–å·¥å…·åç§°
            ext_info = metadata.get('ext_info', {})
            tool_name = ext_info.get('tool_name', 'unknown')
            action_name = ext_info.get('action_name', 'unknown')
            tool_type = f"{tool_name}.{action_name}"
            tool_type_durations[tool_type].append(duration)
    
    # è¿”å›æ•°æ®
    result_data = {
        'llm_durations': llm_durations,
        'tool_durations': tool_durations,
        'tool_type_durations': tool_type_durations,
        'total_llm_time': sum(llm_durations) if llm_durations else 0,
        'total_tool_time': sum(tool_durations) if tool_durations else 0,
        'llm_count': len(llm_durations),
        'tool_count': len(tool_durations),
        'blocking_info': blocking_info  # æ·»åŠ æ‹¦æˆªä¿¡æ¯
    }
    
    if not silent:
        # ç»Ÿè®¡ä¿¡æ¯
        print("=" * 80)
        print(f"è€—æ—¶åˆ†å¸ƒç»Ÿè®¡ - {os.path.basename(file_path)}")
        print("=" * 80)
        
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  LLMè°ƒç”¨æ¬¡æ•°: {result_data['llm_count']}")
        print(f"  å·¥å…·è°ƒç”¨æ¬¡æ•°: {result_data['tool_count']}")
        print(f"  æ€»è°ƒç”¨æ¬¡æ•°: {result_data['llm_count'] + result_data['tool_count']}")
        
        if llm_durations:
            print(f"\nğŸ¤– LLMè°ƒç”¨è€—æ—¶ç»Ÿè®¡ï¼ˆç§’ï¼‰:")
            print(f"  æ€»è€—æ—¶: {result_data['total_llm_time']:.2f}")
            print(f"  å¹³å‡è€—æ—¶: {statistics.mean(llm_durations):.2f}")
            print(f"  ä¸­ä½æ•°è€—æ—¶: {statistics.median(llm_durations):.2f}")
            print(f"  æœ€å°è€—æ—¶: {min(llm_durations):.2f}")
            print(f"  æœ€å¤§è€—æ—¶: {max(llm_durations):.2f}")
            if len(llm_durations) > 1:
                print(f"  æ ‡å‡†å·®: {statistics.stdev(llm_durations):.2f}")
        
        if tool_durations:
            print(f"\nğŸ› ï¸  å·¥å…·è°ƒç”¨è€—æ—¶ç»Ÿè®¡ï¼ˆç§’ï¼‰:")
            print(f"  æ€»è€—æ—¶: {result_data['total_tool_time']:.2f}")
            print(f"  å¹³å‡è€—æ—¶: {statistics.mean(tool_durations):.2f}")
            print(f"  ä¸­ä½æ•°è€—æ—¶: {statistics.median(tool_durations):.2f}")
            print(f"  æœ€å°è€—æ—¶: {min(tool_durations):.2f}")
            print(f"  æœ€å¤§è€—æ—¶: {max(tool_durations):.2f}")
            if len(tool_durations) > 1:
                print(f"  æ ‡å‡†å·®: {statistics.stdev(tool_durations):.2f}")
        
        total_time = result_data['total_llm_time'] + result_data['total_tool_time']
        if total_time > 0:
            print(f"\nğŸ“ˆ è€—æ—¶å æ¯”:")
            print(f"  LLMè°ƒç”¨å æ¯”: {result_data['total_llm_time']/total_time*100:.2f}% ({result_data['total_llm_time']:.2f}ç§’)")
            print(f"  å·¥å…·è°ƒç”¨å æ¯”: {result_data['total_tool_time']/total_time*100:.2f}% ({result_data['total_tool_time']:.2f}ç§’)")
            print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        print("\n" + "=" * 80)
    
    return result_data

def extract_timing_data(data: Dict) -> Dict:
    """ä»æ•°æ®å­—å…¸ä¸­æå–è€—æ—¶å’Œè°ƒç”¨æ¬¡æ•°ä¿¡æ¯"""
    if 'total_time' in data:
        # æ±‡æ€»æ•°æ®ï¼ˆæ¥è‡ªç›®å½•åˆ†æï¼‰
        total_llm_time = data.get('total_llm_time', 0)
        total_tool_time = data.get('total_tool_time', 0)
        total_time = data.get('total_time', total_llm_time + total_tool_time)
        llm_count = int(round(data.get('llm_count', 0)))
        tool_count = int(round(data.get('tool_count', 0)))
    else:
        # å®Œæ•´æ•°æ®ï¼ˆæ¥è‡ªå•ä¸ªæ–‡ä»¶åˆ†æï¼‰
        llm_durations = data.get('llm_durations', [])
        tool_durations = data.get('tool_durations', [])
        total_llm_time = sum(llm_durations) if llm_durations else 0
        total_tool_time = sum(tool_durations) if tool_durations else 0
        total_time = total_llm_time + total_tool_time
        llm_count = len(llm_durations)
        tool_count = len(tool_durations)
    
    return {
        'total_time': total_time,
        'total_llm_time': total_llm_time,
        'total_tool_time': total_tool_time,
        'llm_count': llm_count,
        'tool_count': tool_count
    }

def plot_single_bar_chart(ax, timing_data: Dict, title: str = 'Timing Analysis Report', is_average: bool = False):
    """åœ¨æŒ‡å®šçš„axesä¸Šç»˜åˆ¶å•ä¸ªæŸ±çŠ¶å›¾
    
    Args:
        ax: matplotlib axeså¯¹è±¡
        timing_data: åŒ…å«è€—æ—¶æ•°æ®çš„å­—å…¸
        title: å›¾è¡¨æ ‡é¢˜
        is_average: æ˜¯å¦ä¸ºå¹³å‡å€¼æ•°æ®ï¼ˆTrueè¡¨ç¤ºæ˜¾ç¤ºå¹³å‡å€¼ï¼ŒFalseè¡¨ç¤ºæ˜¾ç¤ºæ€»å€¼ï¼‰
    """
    total_time = timing_data['total_time']
    total_llm_time = timing_data['total_llm_time']
    total_tool_time = timing_data['total_tool_time']
    llm_count = timing_data['llm_count']
    tool_count = timing_data['tool_count']
    
    # å‡†å¤‡æ•°æ®ï¼šä»»åŠ¡å¹³å‡è€—æ—¶ã€LLMè°ƒç”¨å¹³å‡è€—æ—¶ã€å·¥å…·è°ƒç”¨å¹³å‡è€—æ—¶
    categories = ['Total Task', 'LLM Calls', 'Tool Calls']
    times = [total_time, total_llm_time, total_tool_time]
    counts = [llm_count + tool_count, llm_count, tool_count]
    
    # åˆ›å»ºæ ‡ç­¾ï¼ŒTotal Taskä¸åŠ æ‹¬å·ï¼Œå…¶ä»–åŠ ä¸Šè°ƒç”¨æ¬¡æ•°ï¼ˆå¸¦"calls"ï¼‰
    labels = ['Total Task']
    labels.append(f'LLM Calls ({llm_count} calls)')
    labels.append(f'Tool Calls ({tool_count} calls)')
    
    x_pos = range(len(categories))
    width = 0.6
    colors = ['#FFA07A', '#FF6B6B', '#4ECDC4']
    
    bars = ax.bar(x_pos, times, width, color=colors, alpha=0.8, 
                  edgecolor='black', linewidth=1.2)
    
    ax.set_xlabel('Type', fontsize=12, fontweight='bold')
    # æ ¹æ®æ˜¯å¦ä¸ºå¹³å‡å€¼è®¾ç½®Yè½´æ ‡ç­¾
    ylabel = 'Average Time (seconds)' if is_average else 'Total Time (seconds)'
    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xticks(x_pos)
    ax.set_xticklabels(labels, fontsize=11)
    ax.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, time in zip(bars, times):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{time:.1f}s', ha='center', va='bottom',
                fontsize=10, fontweight='bold')
    
    return max(times)  # è¿”å›æœ€å¤§è€—æ—¶ï¼Œç”¨äºç»Ÿä¸€yè½´

def plot_timing_analysis(data: Dict, output_path: str = None):
    """ç”Ÿæˆè€—æ—¶åˆ†æå›¾è¡¨ï¼ŒåŒ…å«æ‹¦æˆªç»Ÿè®¡"""
    timing_data = extract_timing_data(data)
    blocking_stats = data.get('blocking_stats', None)
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºå¹³å‡å€¼æ•°æ®ï¼ˆå¦‚æœæœ‰blocking_statsï¼Œè¯´æ˜æ˜¯ä»ç›®å½•åˆ†æå¾—åˆ°çš„å¹³å‡å€¼ï¼‰
    is_average = blocking_stats is not None
    
    # å¦‚æœæœ‰æ‹¦æˆªç»Ÿè®¡ï¼Œåˆ›å»º2ä¸ªå­å›¾ï¼ˆ1è¡Œ2åˆ—ï¼‰ï¼Œå¦åˆ™åªåˆ›å»º1ä¸ª
    if blocking_stats:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))
        
        # ç¬¬ä¸€ä¸ªå­å›¾ï¼šè€—æ—¶åˆ†æï¼ˆå¹³å‡å€¼ï¼‰
        plot_single_bar_chart(ax1, timing_data, 'Timing Analysis Report', is_average=True)
        
        # ç¬¬äºŒä¸ªå­å›¾ï¼šæ‹¦æˆªç»Ÿè®¡
        plot_blocking_stats(ax2, blocking_stats)
        
        # æ·»åŠ æ€»æ ‡é¢˜
        fig.suptitle('Timing and Blocking Analysis Report', fontsize=16, fontweight='bold', y=1.02)
    else:
        # æ²¡æœ‰æ‹¦æˆªç»Ÿè®¡ï¼Œåªæ˜¾ç¤ºè€—æ—¶åˆ†æï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ–‡ä»¶ï¼Œæ˜¾ç¤ºæ€»å€¼ï¼‰
        fig, ax1 = plt.subplots(figsize=(10, 6))
        plot_single_bar_chart(ax1, timing_data, 'Timing Analysis Report', is_average=False)
    
    # ä¿å­˜å›¾è¡¨
    if output_path is None:
        output_path = 'timing_analysis.png'
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"\nğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()

def plot_blocking_stats(ax, blocking_stats: Dict):
    """åœ¨æŒ‡å®šçš„axesä¸Šç»˜åˆ¶æ‹¦æˆªç»Ÿè®¡æŸ±çŠ¶å›¾"""
    total_files = blocking_stats.get('total_files', 0)
    total_has_answer = blocking_stats.get('total_has_answer', 0)
    login_count = blocking_stats.get('login_blocked_count', 0)
    captcha_count = blocking_stats.get('captcha_blocked_count', 0)
    anti_bot_count = blocking_stats.get('anti_bot_blocked_count', 0)
    
    # å‡†å¤‡æ•°æ®ï¼šåªæ˜¾ç¤º Has Answer å’Œæ‹¦æˆªç±»å‹ç»Ÿè®¡
    categories = ['Has Answer', 'Login', 'Captcha', 'Anti-Bot']
    values = [total_has_answer, login_count, captcha_count, anti_bot_count]
    colors = ['#4ECDC4', '#FF6B6B', '#FFA07A', '#FF4757']
    
    x_pos = range(len(categories))
    width = 0.6
    
    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    bars = ax.bar(x_pos, values, width, color=colors, alpha=0.8, 
                  edgecolor='black', linewidth=1.2)
    
    # è®¾ç½®æ ‡ç­¾
    ax.set_xticks(x_pos)
    ax.set_xticklabels(categories, fontsize=10, rotation=15, ha='right')
    
    ax.set_ylabel('Count', fontsize=12, fontweight='bold')
    ax.set_title('Blocking Statistics', fontsize=14, fontweight='bold')
    ax.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}', ha='center', va='bottom',
                    fontsize=9, fontweight='bold')
    
    # æ·»åŠ æ€»æ•°æ ‡æ³¨
    ax.text(0.02, 0.98, f'Total Files: {total_files}', 
            transform=ax.transAxes, fontsize=10, 
            verticalalignment='top', bbox=dict(boxstyle='round', 
            facecolor='wheat', alpha=0.5))

def plot_multi_level_analysis(level_data_list: List[Dict], output_path: str = None):
    """ç”Ÿæˆå¤šLevelå¯¹æ¯”å›¾è¡¨ï¼Œæ¯ä¸ªLevelä¸€ä¸ªæŸ±çŠ¶å›¾"""
    if len(level_data_list) != 3:
        raise ValueError("éœ€è¦æä¾›3ä¸ªLevelçš„æ•°æ®")
    
    # æå–æ‰€æœ‰Levelçš„æ•°æ®
    timing_data_list = [extract_timing_data(data) for data in level_data_list]
    
    # è®¡ç®—æ‰€æœ‰Levelçš„æœ€å¤§è€—æ—¶ï¼Œç”¨äºç»Ÿä¸€yè½´èŒƒå›´
    max_time = max(td['total_time'] for td in timing_data_list)
    y_max = max_time * 1.15  # ç•™15%çš„é¡¶éƒ¨ç©ºé—´
    
    # åˆ›å»º3ä¸ªå­å›¾ï¼š1è¡Œ3åˆ—
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    level_titles = ['Level 1', 'Level 2', 'Level 3']
    
    for idx, (timing_data, ax) in enumerate(zip(timing_data_list, axes)):
        # ç»˜åˆ¶æŸ±çŠ¶å›¾ï¼ˆå¤šLevelå¯¹æ¯”é€šå¸¸æ˜¯å¹³å‡å€¼ï¼‰
        plot_single_bar_chart(ax, timing_data, level_titles[idx], is_average=True)
        
        # ç»Ÿä¸€yè½´èŒƒå›´
        ax.set_ylim(0, y_max)
        
        # è°ƒæ•´æ ‡ç­¾è§’åº¦ä»¥é€‚åº”3ä¸ªå­å›¾å¸ƒå±€
        ax.set_xticklabels(ax.get_xticklabels(), rotation=15, ha='right', fontsize=10)
        ax.set_xlabel('Type', fontsize=11, fontweight='bold')
        # Yè½´æ ‡ç­¾å·²ç»åœ¨plot_single_bar_chartä¸­è®¾ç½®ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤è®¾ç½®
    
    # æ·»åŠ æ€»æ ‡é¢˜
    fig.suptitle('Multi-Level Timing Analysis', fontsize=16, fontweight='bold', y=1.02)
    
    # ä¿å­˜å›¾è¡¨
    if output_path is None:
        output_path = 'multi_level_timing_analysis.png'
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"\nğŸ“Š å¤šLevelå¯¹æ¯”å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()

def parse_digest_log(log_file_path: str, level_id: str) -> List[float]:
    """ä»digest logæ–‡ä»¶ä¸­è§£ææŒ‡å®šlevel_idçš„æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œè€—æ—¶"""
    task_durations = []
    
    try:
        with open(log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                
                # è§£ææ ¼å¼: eval_task_digest|level_id|task_id|duration|usage_dict
                parts = line.split('|')
                if len(parts) >= 4 and parts[0] == 'eval_task_digest':
                    log_level_id = parts[1]
                    if log_level_id == level_id:
                        try:
                            duration = float(parts[3])
                            task_durations.append(duration)
                        except (ValueError, IndexError):
                            continue
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°logæ–‡ä»¶ {log_file_path}")
        return []
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–logæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []
    
    return task_durations

def analyze_level_from_log(log_file_path: str, level_id: str, trajectory_dir: str = None) -> Dict:
    """ä»logæ–‡ä»¶å’Œtrajectoryç›®å½•åˆ†ælevelæ•°æ®
    
    Total Taskè€—æ—¶: ä»logæ–‡ä»¶ä¸­ç»Ÿè®¡è¯¥level_idçš„æ‰€æœ‰ä»»åŠ¡çš„å¹³å‡è€—æ—¶
    LLM Callså’ŒTool Callsè€—æ—¶: ä»trajectoryç›®å½•ä¸­ç»Ÿè®¡æ¯ä¸ªä»»åŠ¡çš„å¹³å‡å€¼
    LLMå’ŒToolè°ƒç”¨æ¬¡æ•°: ä»trajectoryç›®å½•ä¸­ç»Ÿè®¡æ¯ä¸ªä»»åŠ¡çš„å¹³å‡è°ƒç”¨æ¬¡æ•°
    """
    # 1. ä»logæ–‡ä»¶è·å–ä»»åŠ¡æ€»è€—æ—¶ï¼ˆè¿™æ˜¯Total Taskçš„è€—æ—¶ï¼‰
    task_durations = parse_digest_log(log_file_path, level_id)
    
    if not task_durations:
        print(f"è­¦å‘Š: åœ¨logæ–‡ä»¶ä¸­æœªæ‰¾åˆ° level_id {level_id} çš„ä»»åŠ¡æ•°æ®")
        return None
    
    # è®¡ç®—ä»»åŠ¡å¹³å‡æ€»è€—æ—¶ï¼ˆç”¨äºTotal Taskï¼‰
    avg_task_time = sum(task_durations) / len(task_durations)
    
    # 2. ä»trajectoryç›®å½•è·å–LLMå’Œå·¥å…·è°ƒç”¨è€—æ—¶åŠå¹³å‡è°ƒç”¨æ¬¡æ•°
    # æ¯ä¸ªleveléƒ½æœ‰è‡ªå·±ç‹¬ç«‹çš„trajectoryç›®å½•ï¼Œåˆ†åˆ«è®¡ç®—å¹³å‡å€¼
    if trajectory_dir and os.path.isdir(trajectory_dir):
        trajectory_data = analyze_directory(trajectory_dir, generate_plot=False)
        if trajectory_data:
            # analyze_directoryè¿”å›çš„å·²ç»æ˜¯å¹³å‡å€¼ï¼ˆåŸºäºè¯¥levelç›®å½•ä¸‹çš„æ‰€æœ‰trajæ–‡ä»¶ï¼‰
            avg_llm_time = trajectory_data.get('total_llm_time', 0)
            avg_tool_time = trajectory_data.get('total_tool_time', 0)
            # llm_countå’Œtool_countå·²ç»æ˜¯è¯¥levelçš„å¹³å‡è°ƒç”¨æ¬¡æ•°ï¼ˆå››èˆäº”å…¥åçš„æ•´æ•°ï¼‰
            avg_llm_count = trajectory_data.get('llm_count', 0)
            avg_tool_count = trajectory_data.get('tool_count', 0)
        else:
            print(f"  è­¦å‘Š: æ— æ³•ä»trajectoryç›®å½•è·å–æ•°æ®ï¼ŒLLMå’ŒToolè€—æ—¶è®¾ä¸º0")
            avg_llm_time = 0
            avg_tool_time = 0
            avg_llm_count = 0
            avg_tool_count = 0
    else:
        print(f"  è­¦å‘Š: æœªæ‰¾åˆ°trajectoryç›®å½•ï¼ŒLLMå’ŒToolè€—æ—¶è®¾ä¸º0")
        avg_llm_time = 0
        avg_tool_time = 0
        avg_llm_count = 0
        avg_tool_count = 0
    
    return {
        'total_time': avg_task_time,  # æ¥è‡ªlogæ–‡ä»¶ï¼Œæ‰€æœ‰ä»»åŠ¡çš„å¹³å‡è€—æ—¶
        'total_llm_time': avg_llm_time,  # æ¥è‡ªtrajectoryç›®å½•ï¼Œæ¯ä¸ªä»»åŠ¡çš„å¹³å‡LLMè€—æ—¶
        'total_tool_time': avg_tool_time,  # æ¥è‡ªtrajectoryç›®å½•ï¼Œæ¯ä¸ªä»»åŠ¡çš„å¹³å‡å·¥å…·è€—æ—¶
        'llm_count': avg_llm_count,  # æ¥è‡ªtrajectoryç›®å½•ï¼Œæ¯ä¸ªä»»åŠ¡çš„å¹³å‡LLMè°ƒç”¨æ¬¡æ•°
        'tool_count': avg_tool_count,  # æ¥è‡ªtrajectoryç›®å½•ï¼Œæ¯ä¸ªä»»åŠ¡çš„å¹³å‡å·¥å…·è°ƒç”¨æ¬¡æ•°
        'task_count': len(task_durations)
    }

def analyze_directory(directory_path: str, generate_plot: bool = True):
    """åˆ†æç›®å½•ä¸‹æ‰€æœ‰traj_*.jsonæ–‡ä»¶ï¼Œè®¡ç®—å¹³å‡å€¼"""
    # æŸ¥æ‰¾æ‰€æœ‰traj_*.jsonæ–‡ä»¶
    pattern = os.path.join(directory_path, 'traj_*.json')
    traj_files = glob.glob(pattern)
    
    if not traj_files:
        print(f"åœ¨ç›®å½• {directory_path} ä¸­æœªæ‰¾åˆ° traj_*.json æ–‡ä»¶")
        return None
    
    print(f"æ‰¾åˆ° {len(traj_files)} ä¸ªè½¨è¿¹æ–‡ä»¶")
    print(f"å¼€å§‹åˆ†æ...\n")
    
    # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„æ•°æ®
    all_results = []
    for traj_file in sorted(traj_files):
        try:
            result = analyze_single_trajectory(traj_file, silent=True)
            all_results.append(result)
            print(f"âœ“ å·²å¤„ç†: {os.path.basename(traj_file)}")
        except Exception as e:
            print(f"âœ— å¤„ç†å¤±è´¥ {os.path.basename(traj_file)}: {e}")
            continue
    
    if not all_results:
        print("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")
        return None
    
    # è®¡ç®—å¹³å‡å€¼
    num_files = len(all_results)
    avg_total_llm_time = sum(r['total_llm_time'] for r in all_results) / num_files
    avg_total_tool_time = sum(r['total_tool_time'] for r in all_results) / num_files
    avg_total_time = avg_total_llm_time + avg_total_tool_time
    avg_llm_count = sum(r['llm_count'] for r in all_results) / num_files
    avg_tool_count = sum(r['tool_count'] for r in all_results) / num_files
    
    # è°ƒç”¨æ¬¡æ•°å–æ•´ï¼ˆå› ä¸ºå¹³å‡å€¼å¯èƒ½ä¸ºå°æ•°ï¼‰
    avg_llm_count_int = int(round(avg_llm_count))
    avg_tool_count_int = int(round(avg_tool_count))
    
    # æ±‡æ€»æ‹¦æˆªç»Ÿè®¡
    total_blocked = sum(1 for r in all_results if r.get('blocking_info', {}).get('is_blocked', False))
    total_has_answer = sum(1 for r in all_results if r.get('blocking_info', {}).get('has_answer', False))
    blocked_but_has_answer = sum(1 for r in all_results 
                                 if r.get('blocking_info', {}).get('is_blocked', False) 
                                 and r.get('blocking_info', {}).get('has_answer', False))
    blocked_no_answer = total_blocked - blocked_but_has_answer
    
    # ç»Ÿè®¡å„ç§æ‹¦æˆªç±»å‹
    login_blocked_count = sum(1 for r in all_results if r.get('blocking_info', {}).get('login_blocked', False))
    captcha_blocked_count = sum(1 for r in all_results if r.get('blocking_info', {}).get('captcha_blocked', False))
    anti_bot_blocked_count = sum(1 for r in all_results if r.get('blocking_info', {}).get('anti_bot_blocked', False))
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print(f"å¹³å‡ç»Ÿè®¡ç»“æœ (åŸºäº {num_files} ä¸ªæ–‡ä»¶)")
    print("=" * 80)
    
    print(f"\nğŸ“Š å¹³å‡ç»Ÿè®¡:")
    print(f"  å¹³å‡LLMè°ƒç”¨æ¬¡æ•°: {avg_llm_count:.2f} (çº¦ {avg_llm_count_int})")
    print(f"  å¹³å‡å·¥å…·è°ƒç”¨æ¬¡æ•°: {avg_tool_count:.2f} (çº¦ {avg_tool_count_int})")
    print(f"  å¹³å‡æ€»è°ƒç”¨æ¬¡æ•°: {avg_llm_count + avg_tool_count:.2f} (çº¦ {avg_llm_count_int + avg_tool_count_int})")
    
    print(f"\nğŸ“ˆ å¹³å‡è€—æ—¶:")
    print(f"  å¹³å‡LLMè°ƒç”¨æ€»è€—æ—¶: {avg_total_llm_time:.2f}ç§’")
    print(f"  å¹³å‡å·¥å…·è°ƒç”¨æ€»è€—æ—¶: {avg_total_tool_time:.2f}ç§’")
    print(f"  å¹³å‡ä»»åŠ¡æ€»è€—æ—¶: {avg_total_time:.2f}ç§’")
    
    if avg_total_time > 0:
        print(f"\nğŸ“ˆ å¹³å‡è€—æ—¶å æ¯”:")
        print(f"  LLMè°ƒç”¨å æ¯”: {avg_total_llm_time/avg_total_time*100:.2f}% ({avg_total_llm_time:.2f}ç§’)")
        print(f"  å·¥å…·è°ƒç”¨å æ¯”: {avg_total_tool_time/avg_total_time*100:.2f}% ({avg_total_tool_time:.2f}ç§’)")
    
    # æ‰“å°æ‹¦æˆªç»Ÿè®¡
    print(f"\nğŸš« æ‹¦æˆªç»Ÿè®¡:")
    print(f"  æ­£å¸¸äº§å‡º <answer> çš„æ•°é‡: {total_has_answer} ({total_has_answer/num_files*100:.1f}%)")
    print(f"  è¢«æ‹¦æˆªå½±å“çš„æ•°é‡: {total_blocked} ({total_blocked/num_files*100:.1f}%)")
    print(f"    å…¶ä¸­ï¼šè¢«æ‹¦æˆªä½†ä»äº§å‡ºç­”æ¡ˆ: {blocked_but_has_answer} ({blocked_but_has_answer/num_files*100:.1f}%)")
    print(f"    å…¶ä¸­ï¼šè¢«æ‹¦æˆªä¸”æœªäº§å‡ºç­”æ¡ˆ: {blocked_no_answer} ({blocked_no_answer/num_files*100:.1f}%)")
    print(f"  æ­£å¸¸å®Œæˆï¼ˆæœ‰ç­”æ¡ˆä¸”æœªè¢«æ‹¦æˆªï¼‰: {total_has_answer - blocked_but_has_answer} ({(total_has_answer - blocked_but_has_answer)/num_files*100:.1f}%)")
    print(f"\n  æ‹¦æˆªåŸå› ç»Ÿè®¡ï¼ˆä¸€ä¸ªæ–‡ä»¶å¯èƒ½åŒæ—¶æœ‰å¤šä¸ªæ‹¦æˆªåŸå› ï¼‰:")
    print(f"    ç™»å½•æ‹¦æˆª: {login_blocked_count} æ¬¡")
    print(f"    éªŒè¯ç æ‹¦æˆª: {captcha_blocked_count} æ¬¡")
    print(f"    åçˆ¬è™«æ‹¦æˆª: {anti_bot_blocked_count} æ¬¡")
    
    print("\n" + "=" * 80)
    
    # å‡†å¤‡å›¾è¡¨æ•°æ®
    chart_data = {
        'llm_durations': [],  # è¿™é‡Œä¸éœ€è¦ï¼Œä½†ä¿æŒæ¥å£ä¸€è‡´
        'tool_durations': [],
        'tool_type_durations': {},
        'tool_stats': [],
        'total_llm_time': avg_total_llm_time,
        'total_tool_time': avg_total_tool_time,
        'total_time': avg_total_time,
        'llm_count': avg_llm_count_int,
        'tool_count': avg_tool_count_int,
        'blocking_stats': {
            'total_files': num_files,
            'total_has_answer': total_has_answer,
            'total_blocked': total_blocked,
            'blocked_but_has_answer': blocked_but_has_answer,
            'blocked_no_answer': blocked_no_answer,
            'login_blocked_count': login_blocked_count,
            'captcha_blocked_count': captcha_blocked_count,
            'anti_bot_blocked_count': anti_bot_blocked_count
        }
    }
    
    # ç”Ÿæˆå›¾è¡¨
    if generate_plot:
        output_path = os.path.join(directory_path, 'avg_timing_analysis.png')
        plot_timing_analysis(chart_data, output_path)
    
    return chart_data

if __name__ == '__main__':
    import sys
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  1. å•ä¸ªæ–‡ä»¶: python analyze_timing.py <file_path> [--no-plot]")
        print("  2. å•ä¸ªç›®å½•ï¼ˆæ¨èï¼‰: python analyze_timing.py <directory_path> [--no-plot]")
        print("     åˆ†æç›®å½•ä¸‹æ‰€æœ‰traj_*.jsonæ–‡ä»¶ï¼ŒåŒ…å«è€—æ—¶åˆ†æå’Œæ‹¦æˆªç»Ÿè®¡")
        print("  3. 3ä¸ªLevelå¯¹æ¯”(ç›®å½•): python analyze_timing.py <dir1> <dir2> <dir3> [output_path]")
        print("  4. 3ä¸ªLevelå¯¹æ¯”(Log): python analyze_timing.py --log <log_file> <level_id1> <level_id2> <level_id3> [traj_base_dir] [output_path]")
        sys.exit(1)
    
    # è¿‡æ»¤æ‰--no-plotå‚æ•°
    args = [arg for arg in sys.argv[1:] if arg != '--no-plot']
    generate_plot = '--no-plot' not in sys.argv
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯logæ–‡ä»¶æ¨¡å¼
    if args[0] == '--log' and len(args) >= 5:
        # Logæ–‡ä»¶æ¨¡å¼: --log <log_file> <level_id1> <level_id2> <level_id3> [traj_base_dir] [output_path]
        log_file = args[1]
        level_id1 = args[2]
        level_id2 = args[3]
        level_id3 = args[4]
        
        # å¯é€‰çš„trajectoryåŸºç¡€ç›®å½•ï¼ˆtrajectoryç›®å½•åå°±æ˜¯level_idï¼‰
        traj_base_dir = None
        output_path = None
        
        if len(args) > 5:
            # æ£€æŸ¥ç¬¬5ä¸ªå‚æ•°æ˜¯trajectoryåŸºç¡€ç›®å½•è¿˜æ˜¯output_path
            if os.path.isdir(args[5]):
                traj_base_dir = args[5]
                if len(args) > 6:
                    output_path = args[6]
            else:
                output_path = args[5]
        
        if not os.path.isfile(log_file):
            print(f"é”™è¯¯: logæ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
            sys.exit(1)
        
        print("=" * 80)
        print("å¤šLevelå¯¹æ¯”åˆ†æ (ä»Logæ–‡ä»¶)")
        print("=" * 80)
        
        # åˆ†ææ¯ä¸ªLevel
        level_data_list = []
        level_ids = [level_id1, level_id2, level_id3]
        
        for i, level_id in enumerate(level_ids, 1):
            print(f"\nåˆ†æ Level {i}: {level_id}")
            
            # å¦‚æœæä¾›äº†trajectoryåŸºç¡€ç›®å½•ï¼Œå°è¯•æ‰¾åˆ°å¯¹åº”çš„trajectoryç›®å½•
            traj_dir = None
            if traj_base_dir:
                potential_traj_dir = os.path.join(traj_base_dir, level_id)
                if os.path.isdir(potential_traj_dir):
                    traj_dir = potential_traj_dir
                    print(f"  æ‰¾åˆ°trajectoryç›®å½•: {traj_dir}")
            
            chart_data = analyze_level_from_log(log_file, level_id, traj_dir)
            if chart_data:
                level_data_list.append(chart_data)
                print(f"  æ‰¾åˆ° {chart_data['task_count']} ä¸ªä»»åŠ¡")
                print(f"  å¹³å‡ä»»åŠ¡æ€»è€—æ—¶: {chart_data['total_time']:.2f}ç§’")
                print(f"  å¹³å‡LLMè°ƒç”¨æ¬¡æ•°: {chart_data['llm_count']} æ¬¡")
                print(f"  å¹³å‡å·¥å…·è°ƒç”¨æ¬¡æ•°: {chart_data['tool_count']} æ¬¡")
            else:
                print(f"  è­¦å‘Š: Level {i} åˆ†æå¤±è´¥ï¼Œè·³è¿‡")
        
        if len(level_data_list) == 3:
            if output_path is None:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªlevel_idä½œä¸ºè¾“å‡ºæ–‡ä»¶å
                output_path = f'multi_level_timing_analysis_{level_id1}.png'
            plot_multi_level_analysis(level_data_list, output_path)
        else:
            print("é”™è¯¯: éœ€è¦æˆåŠŸåˆ†æ3ä¸ªLevelæ‰èƒ½ç”Ÿæˆå¯¹æ¯”å›¾")
            sys.exit(1)
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯3ä¸ªç›®å½•æ¨¡å¼
    elif len(args) >= 3:
        # 3ä¸ªLevelå¯¹æ¯”æ¨¡å¼
        dir1 = args[0]
        dir2 = args[1]
        dir3 = args[2]
        output_path = args[3] if len(args) > 3 else None
        
        if not all(os.path.isdir(d) for d in [dir1, dir2, dir3]):
            print("é”™è¯¯: 3ä¸ªLevelæ¨¡å¼éœ€è¦æä¾›3ä¸ªæœ‰æ•ˆçš„ç›®å½•è·¯å¾„")
            sys.exit(1)
        
        print("=" * 80)
        print("å¤šLevelå¯¹æ¯”åˆ†æ")
        print("=" * 80)
        
        # åˆ†ææ¯ä¸ªç›®å½•
        level_data_list = []
        for i, directory in enumerate([dir1, dir2, dir3], 1):
            print(f"\nåˆ†æ Level {i}: {directory}")
            chart_data = analyze_directory(directory, generate_plot=False)
            if chart_data:
                level_data_list.append(chart_data)
            else:
                print(f"è­¦å‘Š: Level {i} åˆ†æå¤±è´¥ï¼Œè·³è¿‡")
        
        if len(level_data_list) == 3:
            if output_path is None:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•
                output_path = os.path.join(dir1, 'multi_level_timing_analysis.png')
            plot_multi_level_analysis(level_data_list, output_path)
        else:
            print("é”™è¯¯: éœ€è¦æˆåŠŸåˆ†æ3ä¸ªLevelæ‰èƒ½ç”Ÿæˆå¯¹æ¯”å›¾")
            sys.exit(1)
    else:
        # å•ä¸ªæ–‡ä»¶æˆ–ç›®å½•æ¨¡å¼
        path = args[0]
        
        if os.path.isfile(path):
            # å•ä¸ªæ–‡ä»¶æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            analyze_single_trajectory(path, silent=False)
            if generate_plot:
                base_name = os.path.splitext(os.path.basename(path))[0]
                output_dir = os.path.dirname(path)
                output_path = os.path.join(output_dir, f'{base_name}_timing_analysis.png')
                result = analyze_single_trajectory(path, silent=True)
                plot_timing_analysis(result, output_path)
        elif os.path.isdir(path):
            # ç›®å½•æ¨¡å¼
            analyze_directory(path, generate_plot=generate_plot)
        else:
            print(f"é”™è¯¯: {path} ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶æˆ–ç›®å½•")
            sys.exit(1)

