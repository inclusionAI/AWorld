#!/usr/bin/env python3
"""
åˆ†æè½¨è¿¹æ–‡ä»¶ä¸­çš„å·¥å…·è°ƒç”¨å’ŒLLMè°ƒç”¨çš„è€—æ—¶åˆ†å¸ƒ
"""
import json
import ast
import os
import glob
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Any, Tuple
import statistics
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
try:
    import matplotlib.font_manager as fm
    # è·å–æ‰€æœ‰å¯ç”¨å­—ä½“
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    # ä¼˜å…ˆä½¿ç”¨çš„ä¸­æ–‡å­—ä½“åˆ—è¡¨
    preferred_fonts = ['PingFang SC', 'STHeiti', 'SimHei', 'Microsoft YaHei', 
                       'Arial Unicode MS', 'WenQuanYi Micro Hei', 'Noto Sans CJK SC']
    
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
    chinese_font = None
    for font in preferred_fonts:
        if font in available_fonts:
            chinese_font = font
            break
    
    if chinese_font:
        matplotlib.rcParams['font.sans-serif'] = [chinese_font] + matplotlib.rcParams['font.sans-serif']
        print(f"ä½¿ç”¨å­—ä½“: {chinese_font}")
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨è‹±æ–‡æ ‡ç­¾
        print("æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾")
        matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']
except Exception as e:
    print(f"å­—ä½“è®¾ç½®å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—ä½“")
    matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']

matplotlib.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

def parse_time(time_str: str) -> datetime:
    """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
    return datetime.fromisoformat(time_str)

def calculate_duration(start_time: str, end_time: str) -> float:
    """è®¡ç®—è€—æ—¶ï¼ˆç§’ï¼‰"""
    start = parse_time(start_time)
    end = parse_time(end_time)
    return (end - start).total_seconds()

def analyze_single_trajectory(file_path: str, silent: bool = False):
    """åˆ†æå•ä¸ªè½¨è¿¹æ–‡ä»¶ï¼Œè¿”å›ç»Ÿè®¡æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå› ä¸ºæ–‡ä»¶å¯èƒ½æ˜¯Pythonå­—å…¸æ ¼å¼è€Œä¸æ˜¯æ ‡å‡†JSON
        content = f.read()
        # å°è¯•ä½¿ç”¨ast.literal_evalè§£æPythonå­—å…¸æ ¼å¼
        try:
            data = ast.literal_eval(content)
        except:
            # å¦‚æœä¸æ˜¯Pythonæ ¼å¼ï¼Œå°è¯•JSON
            data = json.loads(content)
    
    llm_durations = []  # LLMè°ƒç”¨è€—æ—¶
    tool_durations = []  # å·¥å…·è°ƒç”¨è€—æ—¶
    tool_type_durations = defaultdict(list)  # æŒ‰å·¥å…·ç±»å‹åˆ†ç±»çš„è€—æ—¶
    
    # éå†æ‰€æœ‰æ¡ç›®
    for key, entry in data.items():
        if not isinstance(entry, dict):
            continue
            
        metadata = entry.get('metadata', {})
        role = entry.get('role', '')
        start_time = metadata.get('start_time')
        end_time = metadata.get('end_time')
        
        if not start_time or not end_time:
            continue
        
        duration = calculate_duration(start_time, end_time)
        
        # åˆ¤æ–­æ˜¯LLMè°ƒç”¨è¿˜æ˜¯å·¥å…·è°ƒç”¨
        if role == 'assistant':
            # assistantè§’è‰²ä¸”æ²¡æœ‰tool_call_idçš„æ˜¯LLMè°ƒç”¨
            tool_call_id = metadata.get('tool_call_id')
            if not tool_call_id:
                llm_durations.append(duration)
        elif role == 'tool':
            # toolè§’è‰²æ˜¯å·¥å…·è°ƒç”¨
            tool_durations.append(duration)
            # è·å–å·¥å…·åç§°
            ext_info = metadata.get('ext_info', {})
            tool_name = ext_info.get('tool_name', 'unknown')
            action_name = ext_info.get('action_name', 'unknown')
            tool_type = f"{tool_name}.{action_name}"
            tool_type_durations[tool_type].append(duration)
    
    # è¿”å›æ•°æ®
    result_data = {
        'llm_durations': llm_durations,
        'tool_durations': tool_durations,
        'tool_type_durations': tool_type_durations,
        'total_llm_time': sum(llm_durations) if llm_durations else 0,
        'total_tool_time': sum(tool_durations) if tool_durations else 0,
        'llm_count': len(llm_durations),
        'tool_count': len(tool_durations)
    }
    
    if not silent:
        # ç»Ÿè®¡ä¿¡æ¯
        print("=" * 80)
        print(f"è€—æ—¶åˆ†å¸ƒç»Ÿè®¡ - {os.path.basename(file_path)}")
        print("=" * 80)
        
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  LLMè°ƒç”¨æ¬¡æ•°: {result_data['llm_count']}")
        print(f"  å·¥å…·è°ƒç”¨æ¬¡æ•°: {result_data['tool_count']}")
        print(f"  æ€»è°ƒç”¨æ¬¡æ•°: {result_data['llm_count'] + result_data['tool_count']}")
        
        if llm_durations:
            print(f"\nğŸ¤– LLMè°ƒç”¨è€—æ—¶ç»Ÿè®¡ï¼ˆç§’ï¼‰:")
            print(f"  æ€»è€—æ—¶: {result_data['total_llm_time']:.2f}")
            print(f"  å¹³å‡è€—æ—¶: {statistics.mean(llm_durations):.2f}")
            print(f"  ä¸­ä½æ•°è€—æ—¶: {statistics.median(llm_durations):.2f}")
            print(f"  æœ€å°è€—æ—¶: {min(llm_durations):.2f}")
            print(f"  æœ€å¤§è€—æ—¶: {max(llm_durations):.2f}")
            if len(llm_durations) > 1:
                print(f"  æ ‡å‡†å·®: {statistics.stdev(llm_durations):.2f}")
        
        if tool_durations:
            print(f"\nğŸ› ï¸  å·¥å…·è°ƒç”¨è€—æ—¶ç»Ÿè®¡ï¼ˆç§’ï¼‰:")
            print(f"  æ€»è€—æ—¶: {result_data['total_tool_time']:.2f}")
            print(f"  å¹³å‡è€—æ—¶: {statistics.mean(tool_durations):.2f}")
            print(f"  ä¸­ä½æ•°è€—æ—¶: {statistics.median(tool_durations):.2f}")
            print(f"  æœ€å°è€—æ—¶: {min(tool_durations):.2f}")
            print(f"  æœ€å¤§è€—æ—¶: {max(tool_durations):.2f}")
            if len(tool_durations) > 1:
                print(f"  æ ‡å‡†å·®: {statistics.stdev(tool_durations):.2f}")
        
        total_time = result_data['total_llm_time'] + result_data['total_tool_time']
        if total_time > 0:
            print(f"\nğŸ“ˆ è€—æ—¶å æ¯”:")
            print(f"  LLMè°ƒç”¨å æ¯”: {result_data['total_llm_time']/total_time*100:.2f}% ({result_data['total_llm_time']:.2f}ç§’)")
            print(f"  å·¥å…·è°ƒç”¨å æ¯”: {result_data['total_tool_time']/total_time*100:.2f}% ({result_data['total_tool_time']:.2f}ç§’)")
            print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        print("\n" + "=" * 80)
    
    return result_data

def plot_timing_analysis(data: Dict, output_path: str = None):
    """ç”Ÿæˆè€—æ—¶åˆ†æå›¾è¡¨"""
    # æ”¯æŒä¸¤ç§æ•°æ®æ ¼å¼ï¼šå®Œæ•´æ•°æ®æˆ–æ±‡æ€»æ•°æ®
    if 'total_time' in data:
        # æ±‡æ€»æ•°æ®ï¼ˆæ¥è‡ªç›®å½•åˆ†æï¼‰
        total_llm_time = data.get('total_llm_time', 0)
        total_tool_time = data.get('total_tool_time', 0)
        total_time = data.get('total_time', total_llm_time + total_tool_time)
        llm_count = data.get('llm_count', 0)
        tool_count = data.get('tool_count', 0)
    else:
        # å®Œæ•´æ•°æ®ï¼ˆæ¥è‡ªå•ä¸ªæ–‡ä»¶åˆ†æï¼‰
        llm_durations = data.get('llm_durations', [])
        tool_durations = data.get('tool_durations', [])
        total_llm_time = sum(llm_durations) if llm_durations else 0
        total_tool_time = sum(tool_durations) if tool_durations else 0
        total_time = total_llm_time + total_tool_time
        llm_count = len(llm_durations)
        tool_count = len(tool_durations)
    
    # åˆ›å»ºå•ä¸ªæŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # å‡†å¤‡æ•°æ®ï¼šä»»åŠ¡æ€»è€—æ—¶ã€LLMè°ƒç”¨æ€»è€—æ—¶ã€å·¥å…·è°ƒç”¨æ€»è€—æ—¶
    categories = ['Total Task', 'LLM Calls', 'Tool Calls']
    times = [total_time, total_llm_time, total_tool_time]
    counts = [llm_count + tool_count, llm_count, tool_count]
    
    # åˆ›å»ºæ ‡ç­¾ï¼ŒTotal Taskä¸åŠ æ‹¬å·ï¼Œå…¶ä»–åŠ ä¸Šè°ƒç”¨æ¬¡æ•°ï¼ˆå¸¦"calls"ï¼‰
    labels = []
    labels.append('Total Task')  # Total Taskä¸åŠ æ‹¬å·
    labels.append(f'LLM Calls ({llm_count} calls)')
    labels.append(f'Tool Calls ({tool_count} calls)')
    
    x_pos = range(len(categories))
    width = 0.6
    
    # ä½¿ç”¨ä¸åŒé¢œè‰²
    colors = ['#FFA07A', '#FF6B6B', '#4ECDC4']
    
    bars = ax.bar(x_pos, times, width, color=colors, alpha=0.8, 
                  edgecolor='black', linewidth=1.2)
    
    ax.set_xlabel('Type', fontsize=12, fontweight='bold')
    ax.set_ylabel('Total Time (seconds)', fontsize=12, fontweight='bold')
    ax.set_title('Timing Analysis Report', fontsize=14, fontweight='bold')
    ax.set_xticks(x_pos)
    ax.set_xticklabels(labels, fontsize=11)
    ax.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, time in zip(bars, times):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{time:.1f}s', ha='center', va='bottom',
                fontsize=10, fontweight='bold')
    
    # ä¿å­˜å›¾è¡¨
    if output_path is None:
        output_path = 'timing_analysis.png'
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"\nğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()

def analyze_directory(directory_path: str, generate_plot: bool = True):
    """åˆ†æç›®å½•ä¸‹æ‰€æœ‰traj_*.jsonæ–‡ä»¶ï¼Œè®¡ç®—å¹³å‡å€¼"""
    # æŸ¥æ‰¾æ‰€æœ‰traj_*.jsonæ–‡ä»¶
    pattern = os.path.join(directory_path, 'traj_*.json')
    traj_files = glob.glob(pattern)
    
    if not traj_files:
        print(f"åœ¨ç›®å½• {directory_path} ä¸­æœªæ‰¾åˆ° traj_*.json æ–‡ä»¶")
        return None
    
    print(f"æ‰¾åˆ° {len(traj_files)} ä¸ªè½¨è¿¹æ–‡ä»¶")
    print(f"å¼€å§‹åˆ†æ...\n")
    
    # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„æ•°æ®
    all_results = []
    for traj_file in sorted(traj_files):
        try:
            result = analyze_single_trajectory(traj_file, silent=True)
            all_results.append(result)
            print(f"âœ“ å·²å¤„ç†: {os.path.basename(traj_file)}")
        except Exception as e:
            print(f"âœ— å¤„ç†å¤±è´¥ {os.path.basename(traj_file)}: {e}")
            continue
    
    if not all_results:
        print("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")
        return None
    
    # è®¡ç®—å¹³å‡å€¼
    num_files = len(all_results)
    avg_total_llm_time = sum(r['total_llm_time'] for r in all_results) / num_files
    avg_total_tool_time = sum(r['total_tool_time'] for r in all_results) / num_files
    avg_total_time = avg_total_llm_time + avg_total_tool_time
    avg_llm_count = sum(r['llm_count'] for r in all_results) / num_files
    avg_tool_count = sum(r['tool_count'] for r in all_results) / num_files
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print(f"å¹³å‡ç»Ÿè®¡ç»“æœ (åŸºäº {num_files} ä¸ªæ–‡ä»¶)")
    print("=" * 80)
    
    print(f"\nğŸ“Š å¹³å‡ç»Ÿè®¡:")
    print(f"  å¹³å‡LLMè°ƒç”¨æ¬¡æ•°: {avg_llm_count:.2f}")
    print(f"  å¹³å‡å·¥å…·è°ƒç”¨æ¬¡æ•°: {avg_tool_count:.2f}")
    print(f"  å¹³å‡æ€»è°ƒç”¨æ¬¡æ•°: {avg_llm_count + avg_tool_count:.2f}")
    
    print(f"\nğŸ“ˆ å¹³å‡è€—æ—¶:")
    print(f"  å¹³å‡LLMè°ƒç”¨æ€»è€—æ—¶: {avg_total_llm_time:.2f}ç§’")
    print(f"  å¹³å‡å·¥å…·è°ƒç”¨æ€»è€—æ—¶: {avg_total_tool_time:.2f}ç§’")
    print(f"  å¹³å‡ä»»åŠ¡æ€»è€—æ—¶: {avg_total_time:.2f}ç§’")
    
    if avg_total_time > 0:
        print(f"\nğŸ“ˆ å¹³å‡è€—æ—¶å æ¯”:")
        print(f"  LLMè°ƒç”¨å æ¯”: {avg_total_llm_time/avg_total_time*100:.2f}% ({avg_total_llm_time:.2f}ç§’)")
        print(f"  å·¥å…·è°ƒç”¨å æ¯”: {avg_total_tool_time/avg_total_time*100:.2f}% ({avg_total_tool_time:.2f}ç§’)")
    
    print("\n" + "=" * 80)
    
    # å‡†å¤‡å›¾è¡¨æ•°æ®
    chart_data = {
        'llm_durations': [],  # è¿™é‡Œä¸éœ€è¦ï¼Œä½†ä¿æŒæ¥å£ä¸€è‡´
        'tool_durations': [],
        'tool_type_durations': {},
        'tool_stats': [],
        'total_llm_time': avg_total_llm_time,
        'total_tool_time': avg_total_tool_time,
        'total_time': avg_total_time,
        'llm_count': int(round(avg_llm_count)),
        'tool_count': int(round(avg_tool_count))
    }
    
    # ç”Ÿæˆå›¾è¡¨
    if generate_plot:
        output_path = os.path.join(directory_path, 'avg_timing_analysis.png')
        plot_timing_analysis(chart_data, output_path)
    
    return chart_data

if __name__ == '__main__':
    import sys
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python analyze_timing.py <directory_path> [--no-plot]")
        print("      æ‰«æç›®å½•ä¸‹æ‰€æœ‰ traj_*.json æ–‡ä»¶å¹¶è®¡ç®—å¹³å‡å€¼")
        sys.exit(1)
    
    path = sys.argv[1]
    generate_plot = '--no-plot' not in sys.argv
    
    # åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
    if os.path.isfile(path):
        # å•ä¸ªæ–‡ä»¶æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        analyze_single_trajectory(path, silent=False)
        if generate_plot:
            base_name = os.path.splitext(os.path.basename(path))[0]
            output_dir = os.path.dirname(path)
            output_path = os.path.join(output_dir, f'{base_name}_timing_analysis.png')
            result = analyze_single_trajectory(path, silent=True)
            plot_timing_analysis(result, output_path)
    elif os.path.isdir(path):
        # ç›®å½•æ¨¡å¼
        analyze_directory(path, generate_plot=generate_plot)
    else:
        print(f"é”™è¯¯: {path} ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶æˆ–ç›®å½•")
        sys.exit(1)

