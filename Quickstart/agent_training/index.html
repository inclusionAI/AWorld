<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://github.com/inclusionAI/AWorld/Quickstart/agent_training/" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Agent Training - AWorld Docs</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Agent Training";
        var mkdocs_page_input_path = "Quickstart/agent_training.md";
        var mkdocs_page_url = "/inclusionAI/AWorld/Quickstart/agent_training/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> AWorld Docs
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Quickstart</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../install/">Install</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../agent_construction/">Agent Construction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../workflow_construction/">Workflow Construction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../multi-agent_system_construction/">Multi-agent System Construction</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Agent Training</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#installation-example-with-verl">Installation (Example with Verl)</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#setting-up-the-remote-environment">Setting Up the Remote Environment</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#system-requirements">System Requirements</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#operating-system">Operating System</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#hardware">Hardware</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#software">Software</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#login-and-install-the-environment">Login and Install the Environment</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#building-a-custom-agent">Building a Custom Agent</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#implementing-a-custom-agentloop">Implementing a Custom AgentLoop</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#configuration-and-launch">Configuration and Launch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#advanced-scenarios">Advanced Scenarios</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#prepare-for-training">Prepare for Training</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#configuring-the-reward-function">Configuring the Reward Function</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#modifying-the-launch-script">Modifying the Launch Script</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#launching-the-training">Launching the Training</a>
    </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">AWorld Docs</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Quickstart</li>
      <li class="breadcrumb-item active">Agent Training</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/inclusionAI/AWorld/tree/main/docs/Quickstart/agent_training.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="aworld-train">AWorld Train</h1>
<p>AWorld Training bridges AWorld Agents with external training frameworks (e.g., Reinforcement Learning libraries). It is framework-agnostic, enabling you to bring AWorld Agents or Swarms into your preferred training environment.
<img alt="Architecture Diagram" src="../../imgs/train_env_agent_architecture.png" />
The pipeline involves four key steps:</p>
<ol>
<li><strong>Environment Setup (<code>env</code>):</strong> Set up the environment, defining the state/action spaces and interaction dynamics.</li>
<li><strong>Agent Construction (<code>agent</code>):</strong> Build the agent's core logic, policy, and decision-making capabilities.</li>
<li><strong>Framework Adaptation (<code>adapter</code>):</strong> Utilize an adapter to standardize the agent's interface, ensuring compatibility with any RL training frameworks (e.g., Verl).</li>
<li><strong>Training Execution (<code>verl</code>):</strong> Configure the reward function and hyperparameters, then submit the training job via a run script.</li>
</ol>
<h2 id="installation-example-with-verl">Installation (Example with Verl)</h2>
<p>Follow these steps to set up your training environment.</p>
<ol>
<li><strong>Install System-level Prerequisites</strong>:<ul>
<li>Install a compatible <strong>NVIDIA Driver</strong>.</li>
<li>Install the <strong>CUDA Toolkit</strong>.</li>
</ul>
</li>
<li><strong>Manually Install PyTorch</strong>:<ul>
<li>Install a PyTorch version that matches your CUDA version. You can find the command on the <a href="https://pytorch.org/get-started/locally/">PyTorch website</a>.</li>
</ul>
</li>
<li><strong>Install Verl and Dependencies</strong>:<ul>
<li>When you install Verl (e.g., via <code>pip install -e .</code>), other Python packages like <code>transformers</code>, <code>deepspeed</code>, and <code>vllm</code> will be installed automatically.</li>
<li><strong>Important</strong>: This step requires the prerequisites from steps 1 and 2 to succeed, as some packages need to be compiled against CUDA. See <code>setup.py</code> for a full dependency list.</li>
</ul>
</li>
</ol>
<h2 id="setting-up-the-remote-environment">Setting Up the Remote Environment</h2>
<p>Follow these steps to prepare your remote server and launch the environment.</p>
<h3 id="system-requirements">System Requirements</h3>
<h4 id="operating-system">Operating System</h4>
<ul>
<li>The setup is compatible with Windows, macOS, and Linux.</li>
<li>For best performance, a <strong>Linux</strong> system is highly recommended.</li>
<li><strong>Note</strong>: Using a server located in regions such as Singapore or North America is also advised to minimize latency.</li>
</ul>
<h4 id="hardware">Hardware</h4>
<ul>
<li><strong>Minimum</strong>: 4 CPU Cores and 8GB of RAM.</li>
</ul>
<h4 id="software">Software</h4>
<ul>
<li><strong>Docker</strong>: Docker must be installed on your machine.<ul>
<li><strong>Important for Mac Users</strong>: If you are using a Mac with Apple Silicon (M-series), you must enable Rosetta for x86/64 emulation. Please follow the official instructions at: <a href="https://docs.docker.com/desktop/setup/install/mac-install/">Docker for Mac Installation</a>.</li>
</ul>
</li>
</ul>
<h3 id="login-and-install-the-environment">Login and Install the Environment</h3>
<p>Log into your server and follow these steps.</p>
<p><strong>a. Clone the AWorld code to a server directory.</strong></p>
<pre><code class="language-bash">git clone https://github.com/inclusionAI/AWorld ~/AWorld
</code></pre>
<p><strong>b. Configure environment parameters and download the Gaia dataset.</strong></p>
<ul>
<li>
<p><strong>Configure parameters</strong>: Edit the <code>~/AWorld/env/gaia-mcp-server/mcp_servers/.env</code> file and enter your specific configuration values.</p>
<p><code>bash
cd ~/AWorld/env/gaia-mcp-server/mcp_servers
cp .env_template .env</code></p>
</li>
<li>
<p><strong>Download dataset</strong>: Download the <a href="https://huggingface.co/datasets/gaia-benchmark/GAIA">gaia_dataset</a> from Hugging Face and place it in <code>~/AWorld/env/gaia-mcp-server/docker/gaia_dataset</code>.</p>
</li>
</ul>
<p><strong>c. Launch the Gaia Environment.</strong></p>
<p>Run the command below to start the Gaia Environment instance in Docker. The instance will provide:</p>
<ul>
<li>An MCP service on port <code>8000</code> (endpoint: <code>http://localhost:8000/mcp</code>).</li>
<li>A VNC service on port <code>5901</code>. You can view the live interface at <code>http://localhost:5901/vnc.html?autoconnect=true</code>.</li>
</ul>
<pre><code class="language-bash">cd ~/AWorld/env
# Build the Docker image and start the container instance. This process will take approximately 5 minutes.
# Upon success, the following log message will be displayed: Start mcp server success.
sh run-local.sh
</code></pre>
<p><img alt="launch_gaia_env" src="../../imgs/launch_gaia_env.jpg" /></p>
<p><strong>d. Connecting and Testing the Gaia Environment</strong></p>
<p>The URL for the Gaia Environment's MCP service is automatically configured as an environment variable, so no manual endpoint setup is required.</p>
<pre><code class="language-bash">export MCP_SERVER_URL=http://localhost:8080/mcp
</code></pre>
<p>When building an Agent, you use the <code>get_agent_tool_env_and_servers</code> function to configure parameters for making MCP requests and to provide the list of MCP Servers. If this function is called without any arguments, it will automatically use default values.</p>
<pre><code class="language-python">gaia_env_config, gaia_env_servers = get_agent_tool_env_and_servers()
print(f&quot;gaia_env_config: {gaia_env_config}\ngaia_env_servers: {gaia_env_servers}&quot;)

# output
# gaia_env_config: {
#   &quot;mcpServers&quot;: {
#     &quot;aworld-mcp&quot;: {
#       &quot;type&quot;: &quot;streamable-http&quot;,
#       &quot;url&quot;: &quot;http://localhost:8080/mcp&quot;,
#       &quot;headers&quot;: {
#         &quot;MCP_SERVERS&quot;: &quot;readweb-server,browseruse-server,documents-csv-server,documents-docx-server,documents-pptx-server,documents-pdf-server,documents-txt-server,download-server,intelligence-code-server,intelligence-think-server,intelligence-guard-server,media-audio-server,media-image-server,media-video-server,parxiv-server,terminal-server,wayback-server,wiki-server,googlesearch-server&quot;,
#       },
#       &quot;timeout&quot;: 600,
#       &quot;sse_read_timeout&quot;: 600,
#       &quot;client_session_timeout_seconds&quot;: 600,
#     }
#   }
# }
# gaia_env_servers: ['readweb-server', 'browser-server', ...]
</code></pre>
<h2 id="building-a-custom-agent">Building a Custom Agent</h2>
<p>The AWorld framework is designed for flexibility, allowing you to integrate custom agents with external Reinforcement Learning (RL) frameworks (e.g., Verl). This is primarily handled by the <code>adapter</code> module.</p>
<p>The <code>adapter</code> module works by providing the AWorld framework with the LLM's service URL (<code>llm_base_url</code>) and model name (<code>llm_model_name</code>), treating the LLM as a remote service.</p>
<pre><code class="language-python">llm_base_url=self.get_llm_server_address(),
llm_model_name=self.get_llm_server_model_name(),
</code></pre>
<h3 id="implementing-a-custom-agentloop">Implementing a Custom AgentLoop</h3>
<p>To train a custom agent, the primary task is to implement a <code>CustomAgentLoop</code> by inheriting from the <code>AWorldAgentLoop</code> base class.</p>
<p>The following example file, <a href="https://github.com/inclusionAI/AWorld/blob/main/train/examples/train_gaia_with_aworld_verl/custom_agent_loop.py"><code>custom_agent_loop.py</code></a>, demonstrates how to create a custom loop for a single agent using the Verl framework and an environment with five available tools.</p>
<pre><code class="language-python">from aworld.agents.llm_agent import Agent
from aworld.config import AgentConfig
from train.adapter.verl.aworld_agent_loop import AworldAgentLoop
from train.adapter.verl.common import get_agent_tool_env_and_servers

class GaiaAgentLoop(AworldAgentLoop):
    def build_agents(self):
        # Get the environment configuration and server details.
        # Note: The MCP server must be running (Step 1) and the
        # MCP_SERVER_URL/MCP_SERVER_TOKEN environment variables must be set.
        gaia_env_config, gaia_env_servers = get_agent_tool_env_and_servers()

        return Agent(
            conf=AgentConfig(
                # Get the dynamic llm server address from the server manager.
                # The llm server is launched within VeRL.
                llm_base_url=self.get_llm_server_address(),
                llm_model_name=self.get_llm_server_model_name(),
                llm_api_key=&quot;dummy&quot;,
            ),
            name=&quot;gaia_super_agent&quot;,
            system_prompt=&quot;&lt;your_system_prompt&gt;&quot;,

            # MCP tool configuration for the agent, including ms-playwright,google-search,e2b-code-server,image-server and audio-server
            mcp_config=gaia_env_config,
            mcp_servers=gaia_env_servers,
        )
</code></pre>
<h3 id="configuration-and-launch">Configuration and Launch</h3>
<p>Once you have implemented your custom <code>AgentLoop</code>, you need to:</p>
<ol>
<li><strong>Modify the <code>agent.yaml</code> configuration file</strong> to use your new custom loop.</li>
<li><strong>Update the <code>run.sh</code> launch script</strong> to point to your modified <code>agent.yaml</code> file.</li>
</ol>
<pre><code class="language-yaml">- name: gaia_agent
  _target_: train.examples.train_gaia_with_aworld_verl.custom_agent_loop.GaiaAgentLoop
</code></pre>
<pre><code class="language-bash"># Agent config
agent_loop_config_path=${path_to_train}/examples/train_gaia_with_aworld_verl/agent.yaml
</code></pre>
<h3 id="advanced-scenarios">Advanced Scenarios</h3>
<p>AWorld also supports more complex single-agent or multi-agent systems.</p>
<ul>
<li><strong>Agent Construction</strong>: For details on building single-agent or multi-agent systems, please refer to the <a href="https://inclusionai.github.io/AWorld/Quickstart/agent_construction/#"><em>Building and Running an Agent</em></a> and <a href="https://inclusionai.github.io/AWorld/Quickstart/multi-agent_system_construction/"><em>Building and Running a Multi-Agent System</em></a> guides.</li>
<li><strong>MCP Tools</strong>: If your agent requires MCP tools, you must configure the corresponding <code>mcp_config</code> file. Instructions can be found in the <a href=""><em>Building and Running an Agent</em></a> guide.</li>
</ul>
<h2 id="prepare-for-training">Prepare for Training</h2>
<p>After the environment (<code>env</code>) and agent have been set up, the <code>run.sh</code> script is used to initiate the Verl training process. Prior to execution, two final configuration steps are required:</p>
<ol>
<li><strong>Configure the Reward:</strong> Define the reward function according to the specific objectives of the task.</li>
<li><strong>Modify the Launch Script:</strong> Update the <code>run.sh</code> script to set the correct training parameters, such as configuration paths and hyperparameters.</li>
</ol>
<h3 id="configuring-the-reward-function">Configuring the Reward Function</h3>
<p>As an example, here is the reward function used for training the <strong>Gaia</strong> agent. The full code is located in <code>gaia_reward_function.py</code>.</p>
<details>
<summary>Click to view the <code>gaia_reward_function.py</code> implementation</summary>


<pre><code class="language-python">import re
import string
from aworld.logs.util import logger


def normalize_number_str(number_str: str) -&gt; float:
    # we replace these common units and commas to allow
    # conversion to float
    for char in [&quot;$&quot;, &quot;%&quot;, &quot;,&quot;]:
        number_str = number_str.replace(char, &quot;&quot;)
    try:
        return float(number_str)
    except ValueError:
        # print(f&quot;String {number_str} cannot be normalized to number str.&quot;)
        return float(&quot;inf&quot;)

def split_string(
    s: str,
    char_list: list[str] = [&quot;,&quot;, &quot;;&quot;],
) -&gt; list[str]:
    pattern = f&quot;[{''.join(char_list)}]&quot;
    return re.split(pattern, s)

def normalize_str(input_str, remove_punct=True) -&gt; str:
    &quot;&quot;&quot;
    Normalize a string by:
    - Removing all white spaces
    - Optionally removing punctuation (if remove_punct is True)
    - Converting to lowercase
    Parameters:
    - input_str: str, the string to normalize
    - remove_punct: bool, whether to remove punctuation (default: True)
    Returns:
    - str, the normalized string
    &quot;&quot;&quot;
    # Remove all white spaces. Required e.g for seagull vs. sea gull
    no_spaces = re.sub(r&quot;\s&quot;, &quot;&quot;, input_str)

    # Remove punctuation, if specified.
    if remove_punct:
        translator = str.maketrans(&quot;&quot;, &quot;&quot;, string.punctuation)
        return no_spaces.lower().translate(translator)
    else:
        return no_spaces.lower()

def question_scorer(
    model_answer: str,
    ground_truth: str,
) -&gt; bool:
    def is_float(element: any) -&gt; bool:
        try:
            float(element)
            return True
        except ValueError:
            return False

    if model_answer is None:
        model_answer = &quot;None&quot;

    # if gt is a number
    if is_float(ground_truth):
        # print(f&quot;Evaluating {model_answer} as a number.&quot;)
        normalized_answer = normalize_number_str(model_answer)
        return normalized_answer == float(ground_truth)

    # if gt is a list
    elif any(char in ground_truth for char in [&quot;,&quot;, &quot;;&quot;]):
        # print(f&quot;Evaluating {model_answer} as a comma separated list.&quot;)
        # question with the fish: normalization removes punct

        gt_elems = split_string(ground_truth)
        ma_elems = split_string(model_answer)

        # check length is the same
        if len(gt_elems) != len(ma_elems):
            # warnings.warn(
            #     &quot;Answer lists have different lengths, returning False.&quot;, UserWarning
            # )
            return False

        # compare each element as float or str
        comparisons = []
        for ma_elem, gt_elem in zip(ma_elems, gt_elems):
            if is_float(gt_elem):
                normalized_ma_elem = normalize_number_str(ma_elem)
                comparisons.append(normalized_ma_elem == float(gt_elem))
            else:
                # we do not remove punct since comparisons can include punct
                comparisons.append(
                    normalize_str(ma_elem, remove_punct=False)
                    == normalize_str(gt_elem, remove_punct=False)
                )
        return all(comparisons)

    # if gt is a str
    else:
        # print(f&quot;Evaluating {model_answer} as a string.&quot;)
        return normalize_str(model_answer) == normalize_str(ground_truth)


def gaia_reward_func(data_source, solution_str, ground_truth, extra_info=None):
  pattern = r'&lt;answer&gt;(.*?)&lt;/answer&gt;'
  comp_match = re.search(pattern, solution_str, re.DOTALL | re.MULTILINE)

  if not comp_match:
      return 0.0
  else:
      comp_answer = comp_match.group(1).strip()
      logger.info(f&quot;comp_answer: {comp_answer}, ground_truth: {ground_truth}&quot;)
      if question_scorer(comp_answer, ground_truth):
          return 1.0
      else:
          return 0.0
</code></pre>


</details>

<p>After implementing your custom reward function, you must update the <code>run.sh</code> script to point to it:</p>
<pre><code class="language-bash">reward_fn_name=gaia_reward_func
reward_fn_file_path=${path_to_train}/examples/train_gaia_with_aworld_verl/metrics/gaia_reward_function.py
</code></pre>
<h3 id="modifying-the-launch-script">Modifying the Launch Script</h3>
<p>Below is an example of the <code>run.sh</code> script for training a GaiaAgent in the AWorld environment.</p>
<p>In this script, pay close attention to the following key configurations, which are crucial for connecting AWorld to the training framework:</p>
<ul>
<li><code>agent_loop_config_path</code> (Section 3): Specifies the configuration file for your custom AgentLoop.</li>
<li><code>reward_fn_file_path</code> (Section 4.1): Defines the file path where the reward function is located.</li>
<li><code>reward_fn_name</code> (Section 4.1): Specifies the name of the reward function to use.</li>
</ul>
<p>For a detailed explanation of all parameters, please refer to the <a href="https://verl.readthedocs.io/en/latest/examples/config.html"><strong>official VeRL documentation</strong></a>.</p>
<details>
<summary>Click to view the full <code>run.sh</code> script</summary>


<pre><code class="language-shell">#!/usr/bin/env bash

set -xeuo pipefail

# ================= cluster topology =================
export GPUS_PER_NODE=${SLURM_GPUS_ON_NODE:-${GPUS_PER_NODE:-1}}  # GPUs on this node
NNODES=${SLURM_JOB_NUM_NODES:-${NNODES:-1}}
export NNODES
export RAY_NUM_NODES=$NNODES

echo &quot;Using $NNODES nodes and $GPUS_PER_NODE GPUs per node...&quot;

# ================= data/model/tool =================
HDFS_ROOT=${HDFS_ROOT:-$PWD}
DATA_ROOT=${DATA_ROOT:-$PWD}

# Prefer local model if present, otherwise fall back to HF hub path
model_path=${model_path:-$DATA_ROOT/Qwen/Qwen3-4B}
if [ ! -d &quot;$model_path&quot; ]; then
  model_path=Qwen/Qwen3-4B
fi

# Use the default output directory produced by create_dataset.py
train_files=$DATA_ROOT/datasets/train.parquet
test_files=$DATA_ROOT/datasets/test.parquet

# =================== custom ===================
path_to_train=&quot;/your/path/to/train&quot;
reward_fn_name=gaia_reward_func
reward_fn_file_path=${path_to_train}/examples/train_gaia_with_aworld_verl/metrics/gaia_reward_function.py

# Agent config
agent_loop_config_path=${path_to_train}/examples/train_gaia_with_aworld_verl/agent.yaml

# set dummy_tool_config_path to enable auto_tool_choice
dummy_tool_config_path=${path_to_train}/examples/verl/configs/dummy_tool_config.yaml

# =================== wandb ===================
project_name=gaia
experiment_name=qwe3
default_local_dir=$DATA_ROOT/checkpoint/$experiment_name

# ================= algorithm =================
adv_estimator=grpo

use_kl_in_reward=false
kl_coef=0.0
use_kl_loss=false
kl_loss_coef=0.0

clip_ratio_low=0.2
clip_ratio_high=0.28

max_turns=8
max_prompt_length=1024
max_response_length=2048
actor_lr=1e-6

train_batch_size=1
ppo_mini_batch_size=1
n_resp_per_prompt=1
n_resp_per_prompt_val=1

# =================== logging ===================
export RAY_LOGGING_LEVEL=DEBUG
export HYDRA_FULL_ERROR=1

# ================= performance =================
export NCCL_IBEXT_DISABLE=1
export NCCL_NVLS_ENABLE=1
export NCCL_IB_HCA=mlx5
export UCX_NET_DEVICES=mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1
export VLLM_USE_V1=1
export VLLM_ATTENTION_BACKEND=FLASH_ATTN

infer_tp=1  # vLLM tensor parallel size
train_sp=1  # Ulysses sequence parallel size for actor
offload=true

actor_max_token_len_per_gpu=$(( (max_prompt_length + max_response_length) * 4 ))
log_prob_max_token_len_per_gpu=$(( actor_max_token_len_per_gpu * 2 ))

train_files=&quot;['$train_files']&quot;
test_files=&quot;['$test_files']&quot;

python3 -m verl.trainer.main_ppo \
    algorithm.adv_estimator=$adv_estimator \
    algorithm.use_kl_in_reward=$use_kl_in_reward \
    algorithm.kl_ctrl.kl_coef=$kl_coef \
    data.train_files=&quot;$train_files&quot; \
    data.val_files=&quot;$test_files&quot; \
    data.return_raw_chat=true \
    data.train_batch_size=$train_batch_size \
    data.max_prompt_length=$max_prompt_length \
    data.max_response_length=$max_response_length \
    data.filter_overlong_prompts=true \
    data.truncation='error' \
    actor_rollout_ref.model.path=&quot;$model_path&quot; \
    actor_rollout_ref.model.use_remove_padding=true \
    actor_rollout_ref.model.enable_gradient_checkpointing=true \
    actor_rollout_ref.actor.use_kl_loss=$use_kl_loss \
    actor_rollout_ref.actor.kl_loss_coef=$kl_loss_coef \
    actor_rollout_ref.actor.clip_ratio_low=$clip_ratio_low \
    actor_rollout_ref.actor.clip_ratio_high=$clip_ratio_high \
    actor_rollout_ref.actor.clip_ratio_c=10.0 \
    actor_rollout_ref.actor.optim.lr=$actor_lr \
    actor_rollout_ref.actor.use_dynamic_bsz=true \
    actor_rollout_ref.actor.ppo_mini_batch_size=$ppo_mini_batch_size \
    actor_rollout_ref.actor.ppo_max_token_len_per_gpu=$actor_max_token_len_per_gpu \
    actor_rollout_ref.actor.ulysses_sequence_parallel_size=$train_sp \
    actor_rollout_ref.actor.fsdp_config.param_offload=$offload \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=$offload \
    actor_rollout_ref.ref.log_prob_max_token_len_per_gpu=$log_prob_max_token_len_per_gpu \
    actor_rollout_ref.rollout.name=vllm \
    actor_rollout_ref.rollout.mode=async \
    actor_rollout_ref.rollout.tensor_model_parallel_size=$infer_tp \
    actor_rollout_ref.rollout.multi_turn.max_user_turns=$max_turns \
    actor_rollout_ref.rollout.multi_turn.max_assistant_turns=$max_turns \
    actor_rollout_ref.rollout.multi_turn.format=hermes \
    actor_rollout_ref.rollout.agent.agent_loop_config_path=$agent_loop_config_path \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.75 \
    actor_rollout_ref.rollout.n=$n_resp_per_prompt \
    actor_rollout_ref.rollout.val_kwargs.top_p=0.6 \
    actor_rollout_ref.rollout.val_kwargs.temperature=1.0 \
    actor_rollout_ref.rollout.val_kwargs.n=$n_resp_per_prompt_val \
    actor_rollout_ref.rollout.multi_turn.tool_config_path=$dummy_tool_config_path \
    custom_reward_function.path=&quot;${reward_fn_file_path}&quot;\
    custom_reward_function.name=&quot;${reward_fn_name}&quot;\
    trainer.logger=console \
    trainer.project_name=$project_name \
    trainer.experiment_name=$experiment_name \
    trainer.n_gpus_per_node=&quot;$GPUS_PER_NODE&quot; \
    trainer.val_before_train=true \
    trainer.log_val_generations=50 \
    trainer.nnodes=&quot;$NNODES&quot; \
    trainer.save_freq=-1 \
    trainer.default_local_dir=&quot;$default_local_dir&quot; \
    trainer.test_freq=5 \
    trainer.total_epochs=1 &quot;$@&quot;
</code></pre>


</details>

<h2 id="launching-the-training">Launching the Training</h2>
<p>After all configurations are complete, you can start the training by running:</p>
<pre><code class="language-bash">bash run.sh
</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../multi-agent_system_construction/" class="btn btn-neutral float-left" title="Multi-agent System Construction"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>© Copyright 2025 inclusionAI AWorld Team.</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/inclusionAI/AWorld" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../multi-agent_system_construction/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../js/hide-home-edit.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
